{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajDFKMT9m_Qh"
      },
      "source": [
        "Calling all concerned Libraries"
      ],
      "id": "ajDFKMT9m_Qh"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "904ffc56"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import random\n",
        "from sklearn.metrics import confusion_matrix,mean_squared_error\n",
        "from sklearn.svm import SVC \n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.regularizers import l1,l2\n",
        "from tensorflow.keras.optimizers import Adam,RMSprop\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from sklearn import metrics\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "import time"
      ],
      "id": "904ffc56"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDXx5Tc27DuC"
      },
      "source": [
        "# Loading the datasets"
      ],
      "id": "SDXx5Tc27DuC"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "ec043c39",
        "outputId": "8489d050-e16f-4851-cb45-67641de2dc46"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c7d87293-f60c-4bcc-bc43-5537aa425869\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>...</th>\n",
              "      <th>116</th>\n",
              "      <th>117</th>\n",
              "      <th>118</th>\n",
              "      <th>119</th>\n",
              "      <th>120</th>\n",
              "      <th>121</th>\n",
              "      <th>122</th>\n",
              "      <th>123</th>\n",
              "      <th>124</th>\n",
              "      <th>125</th>\n",
              "      <th>126</th>\n",
              "      <th>127</th>\n",
              "      <th>128</th>\n",
              "      <th>129</th>\n",
              "      <th>130</th>\n",
              "      <th>131</th>\n",
              "      <th>132</th>\n",
              "      <th>133</th>\n",
              "      <th>134</th>\n",
              "      <th>135</th>\n",
              "      <th>136</th>\n",
              "      <th>137</th>\n",
              "      <th>138</th>\n",
              "      <th>139</th>\n",
              "      <th>140</th>\n",
              "      <th>141</th>\n",
              "      <th>142</th>\n",
              "      <th>143</th>\n",
              "      <th>144</th>\n",
              "      <th>145</th>\n",
              "      <th>146</th>\n",
              "      <th>147</th>\n",
              "      <th>148</th>\n",
              "      <th>149</th>\n",
              "      <th>150</th>\n",
              "      <th>151</th>\n",
              "      <th>152</th>\n",
              "      <th>153</th>\n",
              "      <th>154</th>\n",
              "      <th>155</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000066</td>\n",
              "      <td>0.000066</td>\n",
              "      <td>0.009150</td>\n",
              "      <td>0.009150</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.36865</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.36867</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.035528</td>\n",
              "      <td>0.035528</td>\n",
              "      <td>0.070588</td>\n",
              "      <td>0.070588</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.36871</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.001459</td>\n",
              "      <td>0.46154</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007936</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.005128</td>\n",
              "      <td>0.005128</td>\n",
              "      <td>0.094771</td>\n",
              "      <td>0.094771</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.36876</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000875</td>\n",
              "      <td>0.46154</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003968</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.007843</td>\n",
              "      <td>0.000031</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.035116</td>\n",
              "      <td>0.035116</td>\n",
              "      <td>0.070588</td>\n",
              "      <td>0.070588</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.36880</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.001459</td>\n",
              "      <td>0.46154</td>\n",
              "      <td>0.004566</td>\n",
              "      <td>0.007936</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 153 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c7d87293-f60c-4bcc-bc43-5537aa425869')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c7d87293-f60c-4bcc-bc43-5537aa425869 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c7d87293-f60c-4bcc-bc43-5537aa425869');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   1  2  3         5         6         8  ...  150  151  152  153  154  155\n",
              "0  0  0  0  0.000066  0.000066  0.009150  ...    0    0    0    0  0.0    0\n",
              "1  0  0  0  0.000014  0.000014  0.000000  ...    0    0    0    0  0.0    0\n",
              "2  0  0  0  0.035528  0.035528  0.070588  ...    0    0    0    0  0.0    0\n",
              "3  0  0  0  0.005128  0.005128  0.094771  ...    0    0    0    0  0.0    0\n",
              "4  0  0  0  0.035116  0.035116  0.070588  ...    0    0    0    0  0.0    0\n",
              "\n",
              "[5 rows x 153 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "train_data=pd.read_csv('train_imperson_without4n7_balanced_data.csv')\n",
        "train_data.head()"
      ],
      "id": "ec043c39"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hp709oy-7QF6"
      },
      "source": [
        "Checking if the datset is balanced and does not contain NULL values"
      ],
      "id": "hp709oy-7QF6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31aa180d",
        "outputId": "d17cafc3-cad3-4773-e7f5-369ef48493d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    48522\n",
              "0    48522\n",
              "Name: 155, dtype: int64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.loc[:,\"155\"].value_counts()"
      ],
      "id": "31aa180d"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "853a5c60",
        "outputId": "93ce1060-19d5-4575-ef3e-11a995e6bfb7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8c31d3ca-333b-48ba-8c97-be6de5208b6c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>...</th>\n",
              "      <th>116</th>\n",
              "      <th>117</th>\n",
              "      <th>118</th>\n",
              "      <th>119</th>\n",
              "      <th>120</th>\n",
              "      <th>121</th>\n",
              "      <th>122</th>\n",
              "      <th>123</th>\n",
              "      <th>124</th>\n",
              "      <th>125</th>\n",
              "      <th>126</th>\n",
              "      <th>127</th>\n",
              "      <th>128</th>\n",
              "      <th>129</th>\n",
              "      <th>130</th>\n",
              "      <th>131</th>\n",
              "      <th>132</th>\n",
              "      <th>133</th>\n",
              "      <th>134</th>\n",
              "      <th>135</th>\n",
              "      <th>136</th>\n",
              "      <th>137</th>\n",
              "      <th>138</th>\n",
              "      <th>139</th>\n",
              "      <th>140</th>\n",
              "      <th>141</th>\n",
              "      <th>142</th>\n",
              "      <th>143</th>\n",
              "      <th>144</th>\n",
              "      <th>145</th>\n",
              "      <th>146</th>\n",
              "      <th>147</th>\n",
              "      <th>148</th>\n",
              "      <th>149</th>\n",
              "      <th>150</th>\n",
              "      <th>151</th>\n",
              "      <th>152</th>\n",
              "      <th>153</th>\n",
              "      <th>154</th>\n",
              "      <th>155</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.002547</td>\n",
              "      <td>0.002547</td>\n",
              "      <td>0.98824</td>\n",
              "      <td>0.98824</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.88219</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.22215</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.47729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.16667</td>\n",
              "      <td>0.16667</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.98674</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.003296</td>\n",
              "      <td>0.003296</td>\n",
              "      <td>0.98824</td>\n",
              "      <td>0.98824</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.88220</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.35106</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.18516</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.16667</td>\n",
              "      <td>0.16667</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.98674</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.003285</td>\n",
              "      <td>0.003285</td>\n",
              "      <td>0.98824</td>\n",
              "      <td>0.98824</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.88220</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.43700</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.47541</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.16667</td>\n",
              "      <td>0.16667</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.98674</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.005942</td>\n",
              "      <td>0.005942</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.88220</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.001519</td>\n",
              "      <td>0.001519</td>\n",
              "      <td>0.98824</td>\n",
              "      <td>0.98824</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.88220</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.63621</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.89971</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.16667</td>\n",
              "      <td>0.16667</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.98674</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 153 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c31d3ca-333b-48ba-8c97-be6de5208b6c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8c31d3ca-333b-48ba-8c97-be6de5208b6c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8c31d3ca-333b-48ba-8c97-be6de5208b6c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   1  2  3         5         6        8  ...  150  151  152  153      154  155\n",
              "0  0  0  0  0.002547  0.002547  0.98824  ...    0    0    0    0  0.98674    0\n",
              "1  0  0  0  0.003296  0.003296  0.98824  ...    0    0    0    0  0.98674    0\n",
              "2  0  0  0  0.003285  0.003285  0.98824  ...    0    0    0    0  0.98674    0\n",
              "3  0  0  0  0.005942  0.005942  0.00000  ...    0    0    0    0  0.00000    0\n",
              "4  0  0  0  0.001519  0.001519  0.98824  ...    0    0    0    0  0.98674    0\n",
              "\n",
              "[5 rows x 153 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "test_data=pd.read_csv('test_imperson_without4n7_balanced_data.csv')\n",
        "test_data.head()"
      ],
      "id": "853a5c60"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10994e90",
        "outputId": "37c7e688-13b9-40ae-b124-53d789764cf6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    20079\n",
              "0    20079\n",
              "Name: 155, dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data.loc[:,\"155\"].value_counts()"
      ],
      "id": "10994e90"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXNGcyzH7Vr5"
      },
      "source": [
        "Checking if there are NULL values"
      ],
      "id": "GXNGcyzH7Vr5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69e10233",
        "outputId": "0ebcb534-7f72-4cc1-a5ab-0d889d3a9fe2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1      0\n",
              "2      0\n",
              "3      0\n",
              "5      0\n",
              "6      0\n",
              "      ..\n",
              "151    0\n",
              "152    0\n",
              "153    0\n",
              "154    0\n",
              "155    0\n",
              "Length: 153, dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.isnull().sum()"
      ],
      "id": "69e10233"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cda19b85",
        "outputId": "8c938ea7-2591-42d1-b56b-b9a9b5db0950"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1      0\n",
              "2      0\n",
              "3      0\n",
              "5      0\n",
              "6      0\n",
              "      ..\n",
              "151    0\n",
              "152    0\n",
              "153    0\n",
              "154    0\n",
              "155    0\n",
              "Length: 153, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data.isnull().sum()"
      ],
      "id": "cda19b85"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfd3FBS-7ax1"
      },
      "source": [
        "# Splitting the test and train datasets into X and Y"
      ],
      "id": "rfd3FBS-7ax1"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "264a77ad"
      },
      "outputs": [],
      "source": [
        "x_train= train_data.iloc[0:,0:152]\n",
        "y_train=train_data.iloc[0:,-1:]\n",
        "x_test= test_data.iloc[0:,0:152]\n",
        "y_test=test_data.iloc[0:,-1:]"
      ],
      "id": "264a77ad"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "18792254",
        "outputId": "672ec1d5-3cb9-476b-82d6-b816aa97d30c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-76d0e66b-1519-40dd-85d5-345e0ac540a1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>...</th>\n",
              "      <th>115</th>\n",
              "      <th>116</th>\n",
              "      <th>117</th>\n",
              "      <th>118</th>\n",
              "      <th>119</th>\n",
              "      <th>120</th>\n",
              "      <th>121</th>\n",
              "      <th>122</th>\n",
              "      <th>123</th>\n",
              "      <th>124</th>\n",
              "      <th>125</th>\n",
              "      <th>126</th>\n",
              "      <th>127</th>\n",
              "      <th>128</th>\n",
              "      <th>129</th>\n",
              "      <th>130</th>\n",
              "      <th>131</th>\n",
              "      <th>132</th>\n",
              "      <th>133</th>\n",
              "      <th>134</th>\n",
              "      <th>135</th>\n",
              "      <th>136</th>\n",
              "      <th>137</th>\n",
              "      <th>138</th>\n",
              "      <th>139</th>\n",
              "      <th>140</th>\n",
              "      <th>141</th>\n",
              "      <th>142</th>\n",
              "      <th>143</th>\n",
              "      <th>144</th>\n",
              "      <th>145</th>\n",
              "      <th>146</th>\n",
              "      <th>147</th>\n",
              "      <th>148</th>\n",
              "      <th>149</th>\n",
              "      <th>150</th>\n",
              "      <th>151</th>\n",
              "      <th>152</th>\n",
              "      <th>153</th>\n",
              "      <th>154</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.002547</td>\n",
              "      <td>0.002547</td>\n",
              "      <td>0.98824</td>\n",
              "      <td>0.98824</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.88219</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.22215</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.47729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.16667</td>\n",
              "      <td>0.16667</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.98674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.003296</td>\n",
              "      <td>0.003296</td>\n",
              "      <td>0.98824</td>\n",
              "      <td>0.98824</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.88220</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.35106</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.18516</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.16667</td>\n",
              "      <td>0.16667</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.98674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.003285</td>\n",
              "      <td>0.003285</td>\n",
              "      <td>0.98824</td>\n",
              "      <td>0.98824</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.88220</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.43700</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.47541</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.16667</td>\n",
              "      <td>0.16667</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.98674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.005942</td>\n",
              "      <td>0.005942</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.88220</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.001519</td>\n",
              "      <td>0.001519</td>\n",
              "      <td>0.98824</td>\n",
              "      <td>0.98824</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.88220</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.63621</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.89971</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.16667</td>\n",
              "      <td>0.16667</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.98674</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 152 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-76d0e66b-1519-40dd-85d5-345e0ac540a1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-76d0e66b-1519-40dd-85d5-345e0ac540a1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-76d0e66b-1519-40dd-85d5-345e0ac540a1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   1  2  3         5         6        8  ...  149  150  151  152  153      154\n",
              "0  0  0  0  0.002547  0.002547  0.98824  ...    0    0    0    0    0  0.98674\n",
              "1  0  0  0  0.003296  0.003296  0.98824  ...    0    0    0    0    0  0.98674\n",
              "2  0  0  0  0.003285  0.003285  0.98824  ...    0    0    0    0    0  0.98674\n",
              "3  0  0  0  0.005942  0.005942  0.00000  ...    0    0    0    0    0  0.00000\n",
              "4  0  0  0  0.001519  0.001519  0.98824  ...    0    0    0    0    0  0.98674\n",
              "\n",
              "[5 rows x 152 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_test.head()"
      ],
      "id": "18792254"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "9072f6c0",
        "outputId": "36511816-50b7-46b2-8db3-a66ca60327d3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-746afa7d-225d-41a3-ab33-3eaa09fb7fe4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>...</th>\n",
              "      <th>115</th>\n",
              "      <th>116</th>\n",
              "      <th>117</th>\n",
              "      <th>118</th>\n",
              "      <th>119</th>\n",
              "      <th>120</th>\n",
              "      <th>121</th>\n",
              "      <th>122</th>\n",
              "      <th>123</th>\n",
              "      <th>124</th>\n",
              "      <th>125</th>\n",
              "      <th>126</th>\n",
              "      <th>127</th>\n",
              "      <th>128</th>\n",
              "      <th>129</th>\n",
              "      <th>130</th>\n",
              "      <th>131</th>\n",
              "      <th>132</th>\n",
              "      <th>133</th>\n",
              "      <th>134</th>\n",
              "      <th>135</th>\n",
              "      <th>136</th>\n",
              "      <th>137</th>\n",
              "      <th>138</th>\n",
              "      <th>139</th>\n",
              "      <th>140</th>\n",
              "      <th>141</th>\n",
              "      <th>142</th>\n",
              "      <th>143</th>\n",
              "      <th>144</th>\n",
              "      <th>145</th>\n",
              "      <th>146</th>\n",
              "      <th>147</th>\n",
              "      <th>148</th>\n",
              "      <th>149</th>\n",
              "      <th>150</th>\n",
              "      <th>151</th>\n",
              "      <th>152</th>\n",
              "      <th>153</th>\n",
              "      <th>154</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000066</td>\n",
              "      <td>0.000066</td>\n",
              "      <td>0.009150</td>\n",
              "      <td>0.009150</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.36865</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.36867</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.035528</td>\n",
              "      <td>0.035528</td>\n",
              "      <td>0.070588</td>\n",
              "      <td>0.070588</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.36871</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.001459</td>\n",
              "      <td>0.46154</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007936</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.005128</td>\n",
              "      <td>0.005128</td>\n",
              "      <td>0.094771</td>\n",
              "      <td>0.094771</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.36876</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000875</td>\n",
              "      <td>0.46154</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003968</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.007843</td>\n",
              "      <td>0.000031</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.035116</td>\n",
              "      <td>0.035116</td>\n",
              "      <td>0.070588</td>\n",
              "      <td>0.070588</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.36880</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.001459</td>\n",
              "      <td>0.46154</td>\n",
              "      <td>0.004566</td>\n",
              "      <td>0.007936</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 152 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-746afa7d-225d-41a3-ab33-3eaa09fb7fe4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-746afa7d-225d-41a3-ab33-3eaa09fb7fe4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-746afa7d-225d-41a3-ab33-3eaa09fb7fe4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   1  2  3         5         6         8  ...  149  150  151  152  153  154\n",
              "0  0  0  0  0.000066  0.000066  0.009150  ...    0    0    0    0    0  0.0\n",
              "1  0  0  0  0.000014  0.000014  0.000000  ...    0    0    0    0    0  0.0\n",
              "2  0  0  0  0.035528  0.035528  0.070588  ...    0    0    0    0    0  0.0\n",
              "3  0  0  0  0.005128  0.005128  0.094771  ...    0    0    0    0    0  0.0\n",
              "4  0  0  0  0.035116  0.035116  0.070588  ...    0    0    0    0    0  0.0\n",
              "\n",
              "[5 rows x 152 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.head()"
      ],
      "id": "9072f6c0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PD0IY2pu7mGw"
      },
      "source": [
        "Looking at the distribution of the datasets"
      ],
      "id": "PD0IY2pu7mGw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "ad04480b",
        "outputId": "d22a396c-518b-4249-d84f-f09c79ec50da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([    0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
              "            0.,     0., 97044.,     0.,     0.,     0.,     0.,     0.,\n",
              "            0.,     0.,     0.,     0.]),\n",
              " array([-0.5 , -0.45, -0.4 , -0.35, -0.3 , -0.25, -0.2 , -0.15, -0.1 ,\n",
              "        -0.05,  0.  ,  0.05,  0.1 ,  0.15,  0.2 ,  0.25,  0.3 ,  0.35,\n",
              "         0.4 ,  0.45,  0.5 ]),\n",
              " <a list of 20 Patch objects>)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD4CAYAAAAZ1BptAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAARFElEQVR4nO3df6xfdX3H8edLOhR/8LtB1rKVxGZLJZvCDWDMdBEGBQ0lmTKMG9U09g9wY3PLhnMJCUiC+yFqpmREGMUYgXUuNKOs6wrGLFmRixhdYYw7FGnHj6tFmCPKqu/9cT+d35X76b2933u/t4XnI/nmnvM+n3PO+9OGvu73fM/3kKpCkqTpvGKxG5AkHbwMCUlSlyEhSeoyJCRJXYaEJKlryWI3MN+OP/74WrFixWK3IUmHlPvvv/+7VbV03/qMIZHkJuBdwNNVdUqrHQvcBqwAvg1cVFXPJAnwKeB84Hng/VX1tbbPWuBP2mE/VlUbWv004GbgCGAzcHlVVe8cM/W7YsUKxsfHZxomSRqQ5LHp6rO53HQzsHqf2hXAtqpaCWxr6wDnASvbaz1wfTv5scCVwBnA6cCVSY5p+1wPfHBgv9UznEOSNCIzhkRVfQXYvU95DbChLW8ALhyo31JTtgNHJzkROBfYWlW727uBrcDqtu3IqtpeU9/qu2WfY013DknSiMz1g+sTquqJtvwkcEJbXgY8PjBuZ6vtr75zmvr+zvEiSdYnGU8yPjk5OYfpSJKmM/TdTe0dwII+22Omc1TVDVU1VlVjS5e+6HMXSdIczTUknmqXimg/n271XcBJA+OWt9r+6sunqe/vHJKkEZlrSGwC1rbltcAdA/VLMuVM4Nl2yWgLcE6SY9oH1ucAW9q255Kc2e6MumSfY013DknSiMzmFtgvAr8KHJ9kJ1N3KV0L3J5kHfAYcFEbvpmp218nmLoF9gMAVbU7ydXAfW3cVVW198PwS/npLbB3tRf7OYckaUTyUntU+NjYWPk9CUk6MEnur6qxfes+lkOS1PWSeyyHdLBaccWdc97329e+cx47kWbPdxKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdQ0VEkl+L8mOJP+a5ItJXpXk5CT3JplIcluSw9vYV7b1ibZ9xcBxPtLqDyc5d6C+utUmklwxTK+SpAM355BIsgz4HWCsqk4BDgMuBj4OXFdVbwCeAda1XdYBz7T6dW0cSVa1/d4IrAY+m+SwJIcBnwHOA1YB721jJUkjMuzlpiXAEUmWAK8GngDeAWxs2zcAF7blNW2dtv2sJGn1W6vqR1X1LWACOL29Jqrq0ap6Abi1jZUkjcicQ6KqdgF/DnyHqXB4Frgf+H5V7WnDdgLL2vIy4PG27542/rjB+j779OovkmR9kvEk45OTk3OdkiRpH8NcbjqGqd/sTwZ+FngNU5eLRq6qbqiqsaoaW7p06WK0IEkvScNcbjob+FZVTVbV/wBfAt4KHN0uPwEsB3a15V3ASQBt+1HA9wbr++zTq0uSRmSYkPgOcGaSV7fPFs4CHgTuAd7dxqwF7mjLm9o6bfvdVVWtfnG7++lkYCXwVeA+YGW7W+pwpj7c3jREv5KkA7Rk5iHTq6p7k2wEvgbsAR4AbgDuBG5N8rFWu7HtciPw+SQTwG6m/tGnqnYkuZ2pgNkDXFZVPwZI8iFgC1N3Tt1UVTvm2q8k6cDNOSQAqupK4Mp9yo8ydWfSvmN/CLync5xrgGumqW8GNg/ToyRp7vzGtSSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1DRUSSY5OsjHJvyV5KMlbkhybZGuSR9rPY9rYJPl0kokk30hy6sBx1rbxjyRZO1A/Lck32z6fTpJh+pUkHZhh30l8CviHqvpF4JeBh4ArgG1VtRLY1tYBzgNWttd64HqAJMcCVwJnAKcDV+4NljbmgwP7rR6yX0nSAZhzSCQ5CngbcCNAVb1QVd8H1gAb2rANwIVteQ1wS03ZDhyd5ETgXGBrVe2uqmeArcDqtu3IqtpeVQXcMnAsSdIIDPNO4mRgEvjrJA8k+VyS1wAnVNUTbcyTwAlteRnw+MD+O1ttf/Wd09RfJMn6JONJxicnJ4eYkiRp0DAhsQQ4Fbi+qt4M/Dc/vbQEQHsHUEOcY1aq6oaqGquqsaVLly706STpZWOYkNgJ7Kyqe9v6RqZC46l2qYj28+m2fRdw0sD+y1ttf/Xl09QlSSMy55CoqieBx5P8QiudBTwIbAL23qG0FrijLW8CLml3OZ0JPNsuS20BzklyTPvA+hxgS9v2XJIz211NlwwcS5I0AkuG3P+3gS8kORx4FPgAU8Fze5J1wGPARW3sZuB8YAJ4vo2lqnYnuRq4r427qqp2t+VLgZuBI4C72kuSNCJDhURVfR0Ym2bTWdOMLeCyznFuAm6apj4OnDJMj5KkufMb15KkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpK6hQyLJYUkeSPL3bf3kJPcmmUhyW5LDW/2VbX2ibV8xcIyPtPrDSc4dqK9utYkkVwzbqyTpwMzHO4nLgYcG1j8OXFdVbwCeAda1+jrgmVa/ro0jySrgYuCNwGrgsy14DgM+A5wHrALe28ZKkkZkqJBIshx4J/C5th7gHcDGNmQDcGFbXtPWadvPauPXALdW1Y+q6lvABHB6e01U1aNV9QJwaxsrSRqRYd9JfBL4Q+Anbf044PtVtaet7wSWteVlwOMAbfuzbfz/1ffZp1d/kSTrk4wnGZ+cnBxySpKkveYcEkneBTxdVffPYz9zUlU3VNVYVY0tXbp0sduRpJeMJUPs+1bggiTnA68CjgQ+BRydZEl7t7Ac2NXG7wJOAnYmWQIcBXxvoL7X4D69uiRpBOb8TqKqPlJVy6tqBVMfPN9dVe8D7gHe3YatBe5oy5vaOm373VVVrX5xu/vpZGAl8FXgPmBlu1vq8HaOTXPtV5J04IZ5J9HzR8CtST4GPADc2Oo3Ap9PMgHsZuoffapqR5LbgQeBPcBlVfVjgCQfArYAhwE3VdWOBehXktQxLyFRVV8GvtyWH2XqzqR9x/wQeE9n/2uAa6apbwY2z0ePkqQD5zeuJUldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKlrziGR5KQk9yR5MMmOJJe3+rFJtiZ5pP08ptWT5NNJJpJ8I8mpA8da28Y/kmTtQP20JN9s+3w6SYaZrCTpwAzzTmIP8PtVtQo4E7gsySrgCmBbVa0EtrV1gPOAle21HrgepkIFuBI4AzgduHJvsLQxHxzYb/UQ/UqSDtCcQ6Kqnqiqr7Xl/wIeApYBa4ANbdgG4MK2vAa4paZsB45OciJwLrC1qnZX1TPAVmB123ZkVW2vqgJuGTiWJGkE5uUziSQrgDcD9wInVNUTbdOTwAlteRnw+MBuO1ttf/Wd09SnO//6JONJxicnJ4eaiyTpp4YOiSSvBf4W+N2qem5wW3sHUMOeYyZVdUNVjVXV2NKlSxf6dJL0sjFUSCT5GaYC4gtV9aVWfqpdKqL9fLrVdwEnDey+vNX2V18+TV2SNCLD3N0U4Ebgoar6xMCmTcDeO5TWAncM1C9pdzmdCTzbLkttAc5Jckz7wPocYEvb9lySM9u5Lhk4liRpBJYMse9bgd8Cvpnk6632x8C1wO1J1gGPARe1bZuB84EJ4HngAwBVtTvJ1cB9bdxVVbW7LV8K3AwcAdzVXpKkEZlzSFTVPwO97y2cNc34Ai7rHOsm4KZp6uPAKXPtUZI0HL9xLUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldB31IJFmd5OEkE0muWOx+JOnl5KAOiSSHAZ8BzgNWAe9Nsmpxu5Kkl4+DOiSA04GJqnq0ql4AbgXWLHJPkvSysWSxG5jBMuDxgfWdwBn7DkqyHljfVn+Q5OER9Dafjge+u9hNjJhzPgD5+Dx3Mjr+PR86fn664sEeErNSVTcANyx2H3OVZLyqxha7j1Fyzi8PzvnQd7BfbtoFnDSwvrzVJEkjcLCHxH3AyiQnJzkcuBjYtMg9SdLLxkF9uamq9iT5ELAFOAy4qap2LHJbC+GQvVQ2BOf88uCcD3GpqsXuQZJ0kDrYLzdJkhaRISFJ6jIkFkmSY5NsTfJI+3nMfsYemWRnkr8cZY/zaTbzTfKmJP+SZEeSbyT5jcXodVgzPUomySuT3Na235tkxei7nF+zmPOHkzzY/l63JZn2nvxDyWwfGZTk15NUkkPytlhDYvFcAWyrqpXAtrbeczXwlZF0tXBmM9/ngUuq6o3AauCTSY4eYY9Dm+WjZNYBz1TVG4DrgEP3q3LMes4PAGNV9UvARuBPR9vl/JrtI4OSvA64HLh3tB3OH0Ni8awBNrTlDcCF0w1KchpwAvCPI+procw436r696p6pC3/J/A0sHRkHc6P2TxKZvDPYiNwVpKMsMf5NuOcq+qeqnq+rW5n6jtPh7LZPjLoaqZ+CfjhKJubT4bE4jmhqp5oy08yFQT/T5JXAH8B/MEoG1sgM853UJLTgcOB/1joxubZdI+SWdYbU1V7gGeB40bS3cKYzZwHrQPuWtCOFt6Mc05yKnBSVd05ysbm20H9PYlDXZJ/Al4/zaaPDq5UVSWZ7l7kS4HNVbXzUPhFcx7mu/c4JwKfB9ZW1U/mt0stpiS/CYwBb1/sXhZS+wXvE8D7F7mVoRkSC6iqzu5tS/JUkhOr6on2j+LT0wx7C/ArSS4FXgscnuQHVXVQ/n815mG+JDkSuBP4aFVtX6BWF9JsHiWzd8zOJEuAo4Dvjaa9BTGrx+ckOZupXxjeXlU/GlFvC2WmOb8OOAX4cvsF7/XApiQXVNX4yLqcB15uWjybgLVteS1wx74Dqup9VfVzVbWCqUtOtxysATELM863PXrl75ia58YR9jafZvMomcE/i3cDd9eh/a3WGeec5M3AXwEXVNW0vyAcYvY756p6tqqOr6oV7b/f7UzN/ZAKCDAkFtO1wK8leQQ4u62TZCzJ5xa1s4Uxm/leBLwNeH+Sr7fXmxan3blpnzHsfZTMQ8DtVbUjyVVJLmjDbgSOSzIBfJj939l20JvlnP+MqXfDf9P+Xg/pZ7DNcs4vCT6WQ5LU5TsJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLU9b/Jgicy9AdgUgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.hist(x_train.loc[:,\"10\"],bins=20)"
      ],
      "id": "ad04480b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "ce61381d",
        "outputId": "5a4a1c80-027f-453f-915f-43f2d1eccadc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([30306.,   399.,   930.,   428.,   399.,   399.,   568.,   437.,\n",
              "          407.,  1699.,   453.,   431.,   413.,   369.,   414.,   403.,\n",
              "          441.,   411.,   423.,   428.]),\n",
              " array([0.      , 0.049993, 0.099986, 0.149979, 0.199972, 0.249965,\n",
              "        0.299958, 0.349951, 0.399944, 0.449937, 0.49993 , 0.549923,\n",
              "        0.599916, 0.649909, 0.699902, 0.749895, 0.799888, 0.849881,\n",
              "        0.899874, 0.949867, 0.99986 ]),\n",
              " <a list of 20 Patch objects>)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.hist(x_test.loc[:,\"140\"],bins=20)"
      ],
      "id": "ce61381d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "45858dbd",
        "outputId": "8377765c-0166-4fe7-c48c-c8c542f2ac9f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([48522.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
              "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
              "            0.,     0.,     0., 48522.]),\n",
              " array([0.  , 0.05, 0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 ,\n",
              "        0.55, 0.6 , 0.65, 0.7 , 0.75, 0.8 , 0.85, 0.9 , 0.95, 1.  ]),\n",
              " <a list of 20 Patch objects>)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.hist(y_train.loc[:,\"155\"],bins=20)"
      ],
      "id": "45858dbd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "8da5362d",
        "outputId": "24f20772-6795-4628-c60f-69a4a6c146fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([20079.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
              "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
              "            0.,     0.,     0., 20079.]),\n",
              " array([0.  , 0.05, 0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 ,\n",
              "        0.55, 0.6 , 0.65, 0.7 , 0.75, 0.8 , 0.85, 0.9 , 0.95, 1.  ]),\n",
              " <a list of 20 Patch objects>)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAUr0lEQVR4nO3dcZBd5X3e8e8TyVA3NkVYG40iyRV2RaYybQXsYDqpXVJiELSDcJuhYiZGdhlkB+jEtaetnPyBB5cZ3MT2DDMEVy4aRMcGE2MXjSOqKCoNk06EtRgqEDbRgiGsKtAGEUhLSiLn1z/uu5lrsau92rt7F0nfz8ydPed33nPO+yKhZ895z703VYUk6dT2U/PdAUnS/DMMJEmGgSTJMJAkYRhIkoCF892BmVq8eHGtXLlyvrshSSeUxx577E+qaujo+gkbBitXrmRkZGS+uyFJJ5QkL0xW9zaRJMkwkCQZBpIkDANJEoaBJAnDQJJED2GQZEWSh5M8nWRfkl9t9bOS7Eyyv/1c1OpJcnuS0SR7k5zfdawNrf3+JBu66hckebLtc3uSzMVgJUmT6+XK4Ajw2apaDVwE3JhkNbAJ2FVVq4BdbR3gcmBVe20E7oROeAA3Ax8ELgRungiQ1ub6rv3W9j80SVKvpg2DqjpYVd9vy38G/ABYBqwDtrZmW4Gr2vI64J7q2A2cmWQpcBmws6oOV9WrwE5gbdt2RlXtrs6XK9zTdSxJ0gAc1zuQk6wEzgMeBZZU1cG26SVgSVteBrzYtdtYqx2rPjZJfc6s3PQ7M973+dv+6Sz2RNKp6O34b1DPE8hJ3gU8AHy6ql7v3tZ+o5/zr0xLsjHJSJKR8fHxuT6dJJ0yegqDJO+gEwRfr6pvt/LL7RYP7eehVj8ArOjafXmrHau+fJL6W1TV5qoarqrhoaG3fM6SJGmGenmaKMBdwA+q6stdm7YBE08EbQAe7Kpf254qugh4rd1O2gFcmmRRmzi+FNjRtr2e5KJ2rmu7jiVJGoBe5gx+HvgY8GSSJ1rt14DbgPuTXAe8AFzdtm0HrgBGgTeATwBU1eEkXwD2tHa3VNXhtnwDcDfwTuCh9pIkDci0YVBVfwBM9dz/JZO0L+DGKY61BdgySX0EOHe6vkiS5obvQJYkGQaSJMNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRK9fQfyliSHkjzVVftmkifa6/mJr8NMsjLJn3dt+2rXPhckeTLJaJLb2/cdk+SsJDuT7G8/F83FQCVJU+vlyuBuYG13oar+ZVWtqao1wAPAt7s2Pzuxrao+1VW/E7geWNVeE8fcBOyqqlXArrYuSRqgacOgqh4BDk+2rf12fzVw77GOkWQpcEZV7W7fkXwPcFXbvA7Y2pa3dtUlSQPS75zBh4CXq2p/V+3sJI8n+f0kH2q1ZcBYV5uxVgNYUlUH2/JLwJKpTpZkY5KRJCPj4+N9dl2SNKHfMLiGn7wqOAi8t6rOAz4DfCPJGb0erF011DG2b66q4aoaHhoammmfJUlHWTjTHZMsBP45cMFErareBN5sy48leRY4BzgALO/afXmrAbycZGlVHWy3kw7NtE+SpJnp58rgF4EfVtVf3/5JMpRkQVt+H52J4ufabaDXk1zU5hmuBR5su20DNrTlDV11SdKA9PJo6b3AHwI/l2QsyXVt03reOnH8YWBve9T0W8Cnqmpi8vkG4D8Do8CzwEOtfhvwkST76QTMbX2MR5I0A9PeJqqqa6aof3yS2gN0HjWdrP0IcO4k9VeAS6brhyRp7vgOZEmSYSBJMgwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJNHb115uSXIoyVNdtc8nOZDkifa6omvb55KMJnkmyWVd9bWtNppkU1f97CSPtvo3k5w2mwOUJE2vlyuDu4G1k9S/UlVr2ms7QJLVdL4b+QNtn99KsiDJAuAO4HJgNXBNawvwxXasvwO8Clx39IkkSXNr2jCoqkeAw9O1a9YB91XVm1X1I2AUuLC9Rqvquar6C+A+YF2SAP8E+Fbbfytw1XGOQZLUp37mDG5KsrfdRlrUasuAF7vajLXaVPX3AH9aVUeOqk8qycYkI0lGxsfH++i6JKnbTMPgTuD9wBrgIPClWevRMVTV5qoarqrhoaGhQZxSkk4JC2eyU1W9PLGc5GvAd9vqAWBFV9PlrcYU9VeAM5MsbFcH3e0lSQMyoyuDJEu7Vj8KTDxptA1Yn+T0JGcDq4DvAXuAVe3JodPoTDJvq6oCHgZ+qe2/AXhwJn2SJM3ctFcGSe4FLgYWJxkDbgYuTrIGKOB54JMAVbUvyf3A08AR4Maq+nE7zk3ADmABsKWq9rVT/HvgviT/AXgcuGvWRidJ6sm0YVBV10xSnvIf7Kq6Fbh1kvp2YPsk9efoPG0kSZonvgNZkmQYSJIMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJ9BAGSbYkOZTkqa7abyT5YZK9Sb6T5MxWX5nkz5M80V5f7drngiRPJhlNcnuStPpZSXYm2d9+LpqLgUqSptbLlcHdwNqjajuBc6vq7wN/BHyua9uzVbWmvT7VVb8TuB5Y1V4Tx9wE7KqqVcCuti5JGqBpw6CqHgEOH1X73ao60lZ3A8uPdYwkS4Ezqmp3VRVwD3BV27wO2NqWt3bVJUkDMhtzBv8KeKhr/ewkjyf5/SQfarVlwFhXm7FWA1hSVQfb8kvAkqlOlGRjkpEkI+Pj47PQdUkS9BkGSX4dOAJ8vZUOAu+tqvOAzwDfSHJGr8drVw11jO2bq2q4qoaHhob66LkkqdvCme6Y5OPAPwMuaf+IU1VvAm+25ceSPAucAxzgJ28lLW81gJeTLK2qg+120qGZ9kmSNDMzujJIshb4d8CVVfVGV30oyYK2/D46E8XPtdtArye5qD1FdC3wYNttG7ChLW/oqkuSBmTaK4Mk9wIXA4uTjAE303l66HRgZ3tCdHd7cujDwC1J/hL4K+BTVTUx+XwDnSeT3klnjmFinuE24P4k1wEvAFfPysgkST2bNgyq6ppJyndN0fYB4IEpto0A505SfwW4ZLp+SJLmju9AliQZBpIkw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEj2GQZItSQ4leaqrdlaSnUn2t5+LWj1Jbk8ymmRvkvO79tnQ2u9PsqGrfkGSJ9s+t7fvSZYkDUivVwZ3A2uPqm0CdlXVKmBXWwe4HFjVXhuBO6ETHnS+P/mDwIXAzRMB0tpc37Xf0eeSJM2hnsKgqh4BDh9VXgdsbctbgau66vdUx27gzCRLgcuAnVV1uKpeBXYCa9u2M6pqd1UVcE/XsSRJA9DPnMGSqjrYll8ClrTlZcCLXe3GWu1Y9bFJ6m+RZGOSkSQj4+PjfXRdktRtViaQ22/0NRvHmuY8m6tquKqGh4aG5vp0knTK6CcMXm63eGg/D7X6AWBFV7vlrXas+vJJ6pKkAeknDLYBE08EbQAe7Kpf254qugh4rd1O2gFcmmRRmzi+FNjRtr2e5KL2FNG1XceSJA3Awl4aJbkXuBhYnGSMzlNBtwH3J7kOeAG4ujXfDlwBjAJvAJ8AqKrDSb4A7GntbqmqiUnpG+g8sfRO4KH2kiQNSE9hUFXXTLHpkknaFnDjFMfZAmyZpD4CnNtLXyRJs893IEuSDANJkmEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEn2EQZKfS/JE1+v1JJ9O8vkkB7rqV3Tt87kko0meSXJZV31tq40m2dTvoCRJx6enbzqbTFU9A6wBSLKAzpfYf4fO11x+pap+s7t9ktXAeuADwM8Cv5fknLb5DuAjwBiwJ8m2qnp6pn2TJB2fGYfBUS4Bnq2qFzrfaT+pdcB9VfUm8KMko8CFbdtoVT0HkOS+1tYwkKQBma05g/XAvV3rNyXZm2RLkkWttgx4savNWKtNVX+LJBuTjCQZGR8fn6WuS5L6DoMkpwFXAr/dSncC76dzC+kg8KV+zzGhqjZX1XBVDQ8NDc3WYSXplDcbt4kuB75fVS8DTPwESPI14Ltt9QCwomu/5a3GMeqSpAGYjdtE19B1iyjJ0q5tHwWeasvbgPVJTk9yNrAK+B6wB1iV5Ox2lbG+tZUkDUhfVwZJfprOU0Cf7Cr/xyRrgAKen9hWVfuS3E9nYvgIcGNV/bgd5yZgB7AA2FJV+/rplyTp+PQVBlX1f4H3HFX72DHa3wrcOkl9O7C9n75IkmbOdyBLkgwDSZJhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSSJWQiDJM8neTLJE0lGWu2sJDuT7G8/F7V6ktyeZDTJ3iTndx1nQ2u/P8mGfvslSerdbF0Z/EJVramq4ba+CdhVVauAXW0d4HJgVXttBO6ETngANwMfBC4Ebp4IEEnS3Jur20TrgK1teStwVVf9nurYDZyZZClwGbCzqg5X1avATmDtHPVNknSU2QiDAn43yWNJNrbakqo62JZfApa05WXAi137jrXaVPWfkGRjkpEkI+Pj47PQdUkSwMJZOMY/qqoDSX4G2Jnkh90bq6qS1Cych6raDGwGGB4enpVjSpJm4cqgqg60n4eA79C55/9yu/1D+3moNT8ArOjafXmrTVWXJA1AX2GQ5KeTvHtiGbgUeArYBkw8EbQBeLAtbwOubU8VXQS81m4n7QAuTbKoTRxf2mqSpAHo9zbREuA7SSaO9Y2q+m9J9gD3J7kOeAG4urXfDlwBjAJvAJ8AqKrDSb4A7Gntbqmqw332TZLUo77CoKqeA/7BJPVXgEsmqRdw4xTH2gJs6ac/kqSZ8R3IkiTDQJJkGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJoo8wSLIiycNJnk6yL8mvtvrnkxxI8kR7XdG1z+eSjCZ5JsllXfW1rTaaZFN/Q5IkHa9+vvbyCPDZqvp+kncDjyXZ2bZ9pap+s7txktXAeuADwM8Cv5fknLb5DuAjwBiwJ8m2qnq6j75Jko7DjMOgqg4CB9vynyX5AbDsGLusA+6rqjeBHyUZBS5s20bb9ymT5L7W1jCQpAGZlTmDJCuB84BHW+mmJHuTbEmyqNWWAS927TbWalPVJzvPxiQjSUbGx8dno+uSJGYhDJK8C3gA+HRVvQ7cCbwfWEPnyuFL/Z5jQlVtrqrhqhoeGhqarcNK0imvnzkDkryDThB8vaq+DVBVL3dt/xrw3bZ6AFjRtfvyVuMYdUnSAPTzNFGAu4AfVNWXu+pLu5p9FHiqLW8D1ic5PcnZwCrge8AeYFWSs5OcRmeSedtM+yVJOn79XBn8PPAx4MkkT7TarwHXJFkDFPA88EmAqtqX5H46E8NHgBur6scASW4CdgALgC1Vta+PfkmSjlM/TxP9AZBJNm0/xj63ArdOUt9+rP0kSXPLdyBLkgwDSZJhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSSJt1EYJFmb5Jkko0k2zXd/JOlU8rYIgyQLgDuAy4HVdL5HefX89kqSTh1vizAALgRGq+q5qvoL4D5g3Tz3SZJOGQvnuwPNMuDFrvUx4INHN0qyEdjYVv9PkmdmeL7FwJ/MZMd8cYZnnH8zHvMJzDGfGk6pMeeLfY/3b09WfLuEQU+qajOwud/jJBmpquFZ6NIJwzGfGhzzyW+uxvt2uU10AFjRtb681SRJA/B2CYM9wKokZyc5DVgPbJvnPknSKeNtcZuoqo4kuQnYASwAtlTVvjk8Zd+3mk5AjvnU4JhPfnMy3lTVXBxXknQCebvcJpIkzSPDQJJ0cofBdB9xkeT0JN9s2x9NsnLwvZxdPYz5M0meTrI3ya4kkz5zfCLp9aNMkvyLJJXkhH4MsZfxJrm6/TnvS/KNQfdxtvXw9/q9SR5O8nj7u33FfPRzNiXZkuRQkqem2J4kt7f/JnuTnN/XCavqpHzRmYh+FngfcBrwv4DVR7W5AfhqW14PfHO++z2AMf8C8Dfb8q+cCmNu7d4NPALsBobnu99z/Ge8CngcWNTWf2a++z2AMW8GfqUtrwaen+9+z8K4PwycDzw1xfYrgIeAABcBj/ZzvpP5yqCXj7hYB2xty98CLkmSAfZxtk075qp6uKreaKu76byn40TW60eZfAH4IvD/Btm5OdDLeK8H7qiqVwGq6tCA+zjbehlzAWe05b8F/O8B9m9OVNUjwOFjNFkH3FMdu4Ezkyyd6flO5jCY7CMulk3VpqqOAK8B7xlI7+ZGL2Pudh2d3yxOZNOOuV0+r6iq3xlkx+ZIL3/G5wDnJPmfSXYnWTuw3s2NXsb8eeCXk4wB24F/PZiuzavj/f/9mN4W7zPQ4CX5ZWAY+Mfz3Ze5lOSngC8DH5/nrgzSQjq3ii6mc+X3SJK/V1V/Oq+9mlvXAHdX1ZeS/EPgvyQ5t6r+ar47dqI4ma8MevmIi79uk2QhncvLVwbSu7nR08d6JPlF4NeBK6vqzQH1ba5MN+Z3A+cC/yPJ83TurW47gSeRe/kzHgO2VdVfVtWPgD+iEw4nql7GfB1wP0BV/SHwN+h8gN3JbFY/xudkDoNePuJiG7ChLf8S8N+rzcycoKYdc5LzgP9EJwhO9HvJMM2Yq+q1qlpcVSuraiWdeZIrq2pkfrrbt17+Xv9XOlcFJFlM57bRc4Ps5CzrZcx/DFwCkOTv0gmD8YH2cvC2Ade2p4ouAl6rqoMzPdhJe5uopviIiyS3ACNVtQ24i87l5CidiZr189fj/vU45t8A3gX8dpsr/+OqunLeOt2nHsd80uhxvDuAS5M8DfwY+LdVdcJe8fY45s8CX0vyb+hMJn/8BP/FjiT30gn1xW0u5GbgHQBV9VU6cyNXAKPAG8An+jrfCf7fS5I0C07m20SSpB4ZBpIkw0CSZBhIkjAMJEkYBpIkDANJEvD/ASmBkez83IGYAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.hist(y_test.loc[:,\"155\"],bins=20)"
      ],
      "id": "8da5362d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdUbdS0B7vpD"
      },
      "source": [
        "#Trial prediction of the dataset using all the features into Logistic Regression Model"
      ],
      "id": "rdUbdS0B7vpD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd9b91a6",
        "outputId": "a327c6c2-4be7-41bf-fea5-04da3fa772a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8707604960406394\n",
            "[[19197   882]\n",
            " [ 4308 15771]]\n"
          ]
        }
      ],
      "source": [
        "model1=LogisticRegression(solver='liblinear')\n",
        "model1.fit(x_train,np.ravel(y_train))\n",
        "p=model1.predict(x_test)\n",
        "acc_model1 = accuracy_score(y_test,p)\n",
        "cm_model1= confusion_matrix(y_test,p)\n",
        "print(acc_model1)\n",
        "print(cm_model1)"
      ],
      "id": "cd9b91a6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlXz81jY76Kz"
      },
      "source": [
        "# Defining first autoencoder model(AE2)..If possible,Please do not run the following cells, as this will create a new autoencoder. The encoder2 has been saved in 'encoded2.h5'"
      ],
      "id": "DlXz81jY76Kz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bf24e8b0"
      },
      "outputs": [],
      "source": [
        "def AE2(input_size,hsize1,code_size,hsize2):\n",
        "    input_l = Input(shape=(input_size))\n",
        "    hidden1= Dense(hsize1, activation='relu')(input_l)\n",
        "    code = Dense(code_size, activation='relu',activity_regularizer = l2(10e-6))(hidden1)\n",
        "    hidden2= Dense(hsize2, activation='relu')(code)\n",
        "    output_l = Dense(input_size, activation='sigmoid')(hidden2)\n",
        "    autoencoder2 = Model(input_l, output_l)\n",
        "    encoded2 = Model(input_l, code)\n",
        "    return autoencoder2, encoded2"
      ],
      "id": "bf24e8b0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWZ2j6C5vonf"
      },
      "source": [
        "The next chunk is not the actual autoencoder, it is just to check the time taken"
      ],
      "id": "IWZ2j6C5vonf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRQTjcxiuPTK",
        "outputId": "e36a18ac-19c9-4e3e-a3bf-726eee465575"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "2427/2427 [==============================] - 6s 2ms/step - loss: 0.1456\n",
            "Epoch 2/15\n",
            "2427/2427 [==============================] - 5s 2ms/step - loss: 0.0194\n",
            "Epoch 3/15\n",
            "2427/2427 [==============================] - 5s 2ms/step - loss: 0.0115\n",
            "Epoch 4/15\n",
            "2427/2427 [==============================] - 5s 2ms/step - loss: 0.0055\n",
            "Epoch 5/15\n",
            "2427/2427 [==============================] - 5s 2ms/step - loss: 0.0036\n",
            "Epoch 6/15\n",
            "2427/2427 [==============================] - 5s 2ms/step - loss: 0.0028\n",
            "Epoch 7/15\n",
            "2427/2427 [==============================] - 5s 2ms/step - loss: 0.0023\n",
            "Epoch 8/15\n",
            "2427/2427 [==============================] - 5s 2ms/step - loss: 0.0020\n",
            "Epoch 9/15\n",
            "2427/2427 [==============================] - 5s 2ms/step - loss: 0.0016\n",
            "Epoch 10/15\n",
            "2427/2427 [==============================] - 5s 2ms/step - loss: 0.0014\n",
            "Epoch 11/15\n",
            "2427/2427 [==============================] - 5s 2ms/step - loss: 0.0012\n",
            "Epoch 12/15\n",
            "2427/2427 [==============================] - 5s 2ms/step - loss: 9.9839e-04\n",
            "Epoch 13/15\n",
            "2427/2427 [==============================] - 5s 2ms/step - loss: 8.7161e-04\n",
            "Epoch 14/15\n",
            "2427/2427 [==============================] - 5s 2ms/step - loss: 7.7002e-04\n",
            "Epoch 15/15\n",
            "2427/2427 [==============================] - 5s 2ms/step - loss: 6.9169e-04\n",
            "Runtime of the program is 83.4817259311676\n"
          ]
        }
      ],
      "source": [
        "# Dummy code just to check the time taken by autoencoder-Not the actual autoencoder#\n",
        "start=time.time()\n",
        "autoencoder2,encoded2= AE2(152,100,50,100)\n",
        "autoencoder2.compile(optimizer= RMSprop(lr=10e-6), loss='mse')\n",
        "autoencoder2.fit(x_train, x_train, epochs=15,batch_size=40)\n",
        "end=time.time()\n",
        "print(f\"Runtime of the program is {end-start}\")"
      ],
      "id": "WRQTjcxiuPTK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMECFupw8CCn"
      },
      "source": [
        "Defining first autoencoder model(AE2)..If possible,Please do not run the following cells, as this will create a new autoencoder. The encoder2 has been saved in 'encoded2.h5'"
      ],
      "id": "IMECFupw8CCn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b43af4f4",
        "outputId": "98b8ef82-6926-48e3-ffe5-ba43d9181b5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "2427/2427 [==============================] - 5s 2ms/step - loss: 0.1470\n",
            "Epoch 2/15\n",
            "2427/2427 [==============================] - 5s 2ms/step - loss: 0.0204\n",
            "Epoch 3/15\n",
            "2427/2427 [==============================] - 5s 2ms/step - loss: 0.0128\n",
            "Epoch 4/15\n",
            "2427/2427 [==============================] - 5s 2ms/step - loss: 0.0067\n",
            "Epoch 5/15\n",
            "2427/2427 [==============================] - 5s 2ms/step - loss: 0.0039\n",
            "Epoch 6/15\n",
            "2427/2427 [==============================] - 5s 2ms/step - loss: 0.0029\n",
            "Epoch 7/15\n",
            "2427/2427 [==============================] - 5s 2ms/step - loss: 0.0023A: 0s - loss: \n",
            "Epoch 8/15\n",
            "2427/2427 [==============================] - 5s 2ms/step - loss: 0.0019\n",
            "Epoch 9/15\n",
            "2427/2427 [==============================] - 5s 2ms/step - loss: 0.0017\n",
            "Epoch 10/15\n",
            "2427/2427 [==============================] - 5s 2ms/step - loss: 0.0014\n",
            "Epoch 11/15\n",
            "2427/2427 [==============================] - 5s 2ms/step - loss: 0.0012\n",
            "Epoch 12/15\n",
            "2427/2427 [==============================] - 5s 2ms/step - loss: 0.0011\n",
            "Epoch 13/15\n",
            "2427/2427 [==============================] - 5s 2ms/step - loss: 9.4567e-04\n",
            "Epoch 14/15\n",
            "2427/2427 [==============================] - 5s 2ms/step - loss: 8.2909e-04\n",
            "Epoch 15/15\n",
            "2427/2427 [==============================] - 5s 2ms/step - loss: 7.3327e-04\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x250800b0a30>"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "autoencoder2,encoded2= AE2(152,100,50,100)\n",
        "autoencoder2.compile(optimizer= RMSprop(lr=10e-6), loss='mse')\n",
        "autoencoder2.fit(x_train, x_train, epochs=15,batch_size=40)"
      ],
      "id": "b43af4f4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7513412a",
        "outputId": "e875e969-93b6-4d16-c9fa-8c35ea7eced3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Squared Error: 0.0161755669548177\n"
          ]
        }
      ],
      "source": [
        "predictions2=autoencoder2.predict(x_test)\n",
        "print('Mean Squared Error:', metrics.mean_squared_error(x_test, predictions2))"
      ],
      "id": "7513412a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b21c9c2a",
        "outputId": "cbb99d06-0147-4598-d380-5e3cca957ada"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_29\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_15 (InputLayer)       [(None, 152)]             0         \n",
            "                                                                 \n",
            " dense_52 (Dense)            (None, 100)               15300     \n",
            "                                                                 \n",
            " dense_53 (Dense)            (None, 50)                5050      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,350\n",
            "Trainable params: 20,350\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "encoded2.summary()"
      ],
      "id": "b21c9c2a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GjQqKMc8SJJ"
      },
      "source": [
        "# Please do not run this cell. Running it will overwrite the encoder model already saved and hence differ from the results throughout till the end"
      ],
      "id": "6GjQqKMc8SJJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69383eb3"
      },
      "outputs": [],
      "source": [
        "# Please do not run this cell...Encoder model will be overwritten # \n",
        "encoded2.compile(optimizer=RMSprop(lr=10e-6),loss='mse')\n",
        "encoded2.save('encoded2.h5')"
      ],
      "id": "69383eb3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gskYFAb8oXW"
      },
      "source": [
        "Even if the above cells were run for verification.Please load the 'encoded2.h5' mailed to the TA only and not if it is overwritten here."
      ],
      "id": "1gskYFAb8oXW"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyH8BMEd8_F-"
      },
      "source": [
        "# Using the encoded or code layer to predict class variables thorugh Logistic Regression to ascertain encoding was successful"
      ],
      "id": "zyH8BMEd8_F-"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08f9fc0f",
        "outputId": "b0e4031a-0c82-458a-d9dc-c7114756c8b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9350316250809303\n",
            "[[17498  2581]\n",
            " [   28 20051]]\n"
          ]
        }
      ],
      "source": [
        "# This code block can be run.....\n",
        "# load the model from file\n",
        "encoder2 = load_model('encoded2.h5')\n",
        "# encode the train data\n",
        "x_train_encode2 = encoder2.predict(x_train)\n",
        "# encode the test data\n",
        "x_test_encode2 = encoder2.predict(x_test)\n",
        "# define the model\n",
        "model2 = LogisticRegression(solver='liblinear')\n",
        "# fit the model on the training set\n",
        "model2.fit(x_train_encode2, np.ravel(y_train))\n",
        "# make predictions on the test set\n",
        "yhat2 = model2.predict(x_test_encode2)\n",
        "# calculate classification accuracy\n",
        "acc = accuracy_score(y_test, yhat2)\n",
        "print(acc)\n",
        "cm = confusion_matrix(y_test,yhat2)\n",
        "print(cm)"
      ],
      "id": "08f9fc0f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7Bu62Ks9U62"
      },
      "source": [
        "# Defining second autoencoder model(AE3)..If possible, Please do not run the following cells, as this will create a new autoencoder. The encoder3 has been saved in 'encoded3.h5'"
      ],
      "id": "C7Bu62Ks9U62"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99431f8f"
      },
      "outputs": [],
      "source": [
        "def AE3(input_size,hsize1,hsize2,code_size,hsize3,hsize4):\n",
        "    np.random.seed(100)\n",
        "    input_l = Input(shape=(input_size,))\n",
        "    hidden1= Dense(hsize1, activation='relu')(input_l)\n",
        "    hidden2= Dense(hsize2, activation='relu')(hidden1)\n",
        "    code = Dense(code_size, activation='relu',activity_regularizer = l2(10e-6))(hidden2)\n",
        "    hidden3= Dense(hsize3, activation='relu')(code)\n",
        "    hidden4= Dense(hsize4, activation='relu')(hidden3)\n",
        "    output_l = Dense(input_size, activation='sigmoid')(hidden4)\n",
        "    autoencoder3 = Model(input_l, output_l)\n",
        "    encoded3 = Model(input_l, code)\n",
        "    return autoencoder3, encoded3"
      ],
      "id": "99431f8f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXyDP2d0wqhd"
      },
      "source": [
        "The next code chunk is a dummy chunk just to check time taken by autoencoder"
      ],
      "id": "LXyDP2d0wqhd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkSB1KIZwSxX",
        "outputId": "80ebc121-eb30-4602-a102-bfbfe8665b7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "2427/2427 [==============================] - 7s 2ms/step - loss: 0.1617\n",
            "Epoch 2/15\n",
            "2427/2427 [==============================] - 5s 2ms/step - loss: 0.0217\n",
            "Epoch 3/15\n",
            "2427/2427 [==============================] - 6s 2ms/step - loss: 0.0128\n",
            "Epoch 4/15\n",
            "2427/2427 [==============================] - 6s 2ms/step - loss: 0.0071\n",
            "Epoch 5/15\n",
            "2427/2427 [==============================] - 6s 2ms/step - loss: 0.0041\n",
            "Epoch 6/15\n",
            "2427/2427 [==============================] - 6s 2ms/step - loss: 0.0029\n",
            "Epoch 7/15\n",
            "2427/2427 [==============================] - 6s 2ms/step - loss: 0.0024\n",
            "Epoch 8/15\n",
            "2427/2427 [==============================] - 6s 2ms/step - loss: 0.0021\n",
            "Epoch 9/15\n",
            "2427/2427 [==============================] - 6s 2ms/step - loss: 0.0018\n",
            "Epoch 10/15\n",
            "2427/2427 [==============================] - 6s 2ms/step - loss: 0.0016\n",
            "Epoch 11/15\n",
            "2427/2427 [==============================] - 6s 2ms/step - loss: 0.0014\n",
            "Epoch 12/15\n",
            "2427/2427 [==============================] - 6s 2ms/step - loss: 0.0013\n",
            "Epoch 13/15\n",
            "2427/2427 [==============================] - 6s 2ms/step - loss: 0.0011\n",
            "Epoch 14/15\n",
            "2427/2427 [==============================] - 6s 2ms/step - loss: 0.0010\n",
            "Epoch 15/15\n",
            "2427/2427 [==============================] - 6s 2ms/step - loss: 9.2758e-04\n",
            "Runtime of the program is 143.74262189865112\n"
          ]
        }
      ],
      "source": [
        "# Dummy chunk just to check the time taken by autoencoder # \n",
        "start = time.time()\n",
        "autoencoder3,encoded3= AE3(152,100,50,25,50,100)\n",
        "autoencoder3.compile(optimizer=RMSprop(lr=10e-6), loss='mse')\n",
        "autoencoder3.fit(x_train, x_train, epochs=15,batch_size=40)\n",
        "end=time.time()\n",
        "print(f\"Runtime of the program is {end-start}\")"
      ],
      "id": "JkSB1KIZwSxX"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4g3FYH749dWK"
      },
      "source": [
        "Please,Do not run the following cell, if possible....New autoencoder will be created"
      ],
      "id": "4g3FYH749dWK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1a7052c0",
        "outputId": "3b50be34-c3da-4ad4-90ee-ab59f78cbff0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "2427/2427 [==============================] - 5s 2ms/step - loss: 0.1680\n",
            "Epoch 2/15\n",
            "2427/2427 [==============================] - 5s 2ms/step - loss: 0.0232\n",
            "Epoch 3/15\n",
            "2427/2427 [==============================] - 5s 2ms/step - loss: 0.0140\n",
            "Epoch 4/15\n",
            "2427/2427 [==============================] - 5s 2ms/step - loss: 0.0084\n",
            "Epoch 5/15\n",
            "2427/2427 [==============================] - 4s 2ms/step - loss: 0.0052\n",
            "Epoch 6/15\n",
            "2427/2427 [==============================] - 5s 2ms/step - loss: 0.0035\n",
            "Epoch 7/15\n",
            "2427/2427 [==============================] - 4s 2ms/step - loss: 0.0027\n",
            "Epoch 8/15\n",
            "2427/2427 [==============================] - 5s 2ms/step - loss: 0.0022\n",
            "Epoch 9/15\n",
            "2427/2427 [==============================] - 5s 2ms/step - loss: 0.0019\n",
            "Epoch 10/15\n",
            "2427/2427 [==============================] - 4s 2ms/step - loss: 0.0017\n",
            "Epoch 11/15\n",
            "2427/2427 [==============================] - 5s 2ms/step - loss: 0.0015\n",
            "Epoch 12/15\n",
            "2427/2427 [==============================] - 5s 2ms/step - loss: 0.0013\n",
            "Epoch 13/15\n",
            "2427/2427 [==============================] - 4s 2ms/step - loss: 0.0012\n",
            "Epoch 14/15\n",
            "2427/2427 [==============================] - 4s 2ms/step - loss: 0.0010\n",
            "Epoch 15/15\n",
            "2427/2427 [==============================] - 4s 2ms/step - loss: 9.4239e-04\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x25082aa62e0>"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Actual autoencoder code,running it will create a new one and results below may differ# \n",
        "autoencoder3,encoded3= AE3(152,100,50,25,50,100)\n",
        "autoencoder3.compile(optimizer=RMSprop(lr=10e-6), loss='mse')\n",
        "autoencoder3.fit(x_train, x_train, epochs=15,batch_size=40)"
      ],
      "id": "1a7052c0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cd5a74d1",
        "outputId": "eb238432-fd38-495f-ecf8-3520374c787c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Squared Error: 0.01842191208700395\n"
          ]
        }
      ],
      "source": [
        "predictions3=autoencoder3.predict(x_test)\n",
        "print('Mean Squared Error:', metrics.mean_squared_error(x_test, predictions3))"
      ],
      "id": "cd5a74d1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxdMpagl9q0y"
      },
      "source": [
        "# Please do not run this cell. The existing encoder model will be overwritten and results throughout may vary"
      ],
      "id": "BxdMpagl9q0y"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ca0d03fb"
      },
      "outputs": [],
      "source": [
        "# Please do not run this cell...Encoder model will be overwritten # \n",
        "encoded3.compile(optimizer=RMSprop(lr=10e-6), loss='mse')\n",
        "encoded3.save('encoded3.h5')"
      ],
      "id": "ca0d03fb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bx5UdJ1q-pn0"
      },
      "source": [
        "Even if the above cells were run for verification.Please load the 'encoded3.h5' mailed to the TA only and not if it is overwritten here."
      ],
      "id": "Bx5UdJ1q-pn0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_a1nwlKz_D7w"
      },
      "source": [
        "# Using the encoded or code layer to predict class variables through Logistic Regression to ascertain encoding was successful"
      ],
      "id": "_a1nwlKz_D7w"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6554bb96",
        "outputId": "0fc1166f-86e4-4115-cb45-edebdf629e56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9426515264704417\n",
            "[[19249   830]\n",
            " [ 1473 18606]]\n"
          ]
        }
      ],
      "source": [
        "# Can run all the cells from here\n",
        "# load the model from file\n",
        "encoder3 = load_model('encoded3.h5')\n",
        "# encode the train data\n",
        "x_train_encode3 = encoder3.predict(x_train)\n",
        "# encode the test data\n",
        "x_test_encode3 = encoder3.predict(x_test)\n",
        "# define the model\n",
        "model3 = LogisticRegression(solver='liblinear')\n",
        "# fit the model on the training set\n",
        "model3.fit(x_train_encode3, np.ravel(y_train))\n",
        "# make predictions on the test set\n",
        "yhat3 = model3.predict(x_test_encode3)\n",
        "# calculate classification accuracy\n",
        "acc = accuracy_score(y_test, yhat3)\n",
        "print(acc)\n",
        "cm = confusion_matrix(y_test,yhat3)\n",
        "print(cm)"
      ],
      "id": "6554bb96"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_Fv_Myn_bHo"
      },
      "source": [
        "# Checking PCA for feature extraction and using the principal components to predict class variables through Logistic Regression"
      ],
      "id": "V_Fv_Myn_bHo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "616c0e6a"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "x_train_st = sc.fit_transform(x_train)\n",
        "x_test_st = sc.transform(x_test)"
      ],
      "id": "616c0e6a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANNj-kyR_jp5"
      },
      "outputs": [],
      "source": [
        "# we put 0.95 here to return as few principal components as possible which account for 95% variation\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(0.95)\n",
        "x_train_st = pca.fit_transform(x_train_st)\n",
        "x_test_st = pca.transform(x_test_st)"
      ],
      "id": "ANNj-kyR_jp5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gch91-x__nBU",
        "outputId": "ab596be3-0bc4-4a94-923f-1cd03f53f82f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[12.78968019 11.98783161  7.75024674  5.08228454  3.42978889  3.06246381\n",
            "  2.82046923  2.45916195  2.15037393  1.95035693  1.74245582  1.64786638\n",
            "  1.467943    1.35781713  1.33749314  1.19347954  1.10531897  1.05851075\n",
            "  1.0141258   1.0066591   1.00052358  0.93934526  0.90587771  0.8443942\n",
            "  0.74703886  0.70382278  0.66673511  0.57962807  0.56661605  0.55247339\n",
            "  0.5323229 ]\n"
          ]
        }
      ],
      "source": [
        "print(pca.explained_variance_)"
      ],
      "id": "gch91-x__nBU"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgbBEMAe43i2"
      },
      "source": [
        "As we see above , that 31 principal components account for 95% variation which is a lot. hence entering n_components =31 below"
      ],
      "id": "PgbBEMAe43i2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROEvwpo8_r9Z"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=31)\n",
        "x_train_st = pca.fit_transform(x_train_st)\n",
        "x_test_st = pca.transform(x_test_st)"
      ],
      "id": "ROEvwpo8_r9Z"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJ7rqEHH_tqk",
        "outputId": "c96ac5c0-6bb3-459d-feb5-5012c27c57e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5172070322227202\n",
            "[[19303   776]\n",
            " [18612  1467]]\n"
          ]
        }
      ],
      "source": [
        "modelpca=LogisticRegression(solver='liblinear')\n",
        "modelpca.fit(x_train_st,np.ravel(y_train))\n",
        "p=modelpca.predict(x_test_st)\n",
        "acc_modelpca = accuracy_score(y_test,p)\n",
        "cm_modelpca= confusion_matrix(y_test,p)\n",
        "print(acc_modelpca)\n",
        "print(cm_modelpca)"
      ],
      "id": "JJ7rqEHH_tqk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHVWpo2r5EoR"
      },
      "source": [
        "As we see above, we get only 51% accuracy with PCA. Hence using autoencoders for feature extraction is a better option"
      ],
      "id": "gHVWpo2r5EoR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzOeTBWf_5IU"
      },
      "source": [
        "# Going ahead with autoencoder models as extracted features of autoencoders predicted better"
      ],
      "id": "uzOeTBWf_5IU"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjE2jEKJ__MW"
      },
      "source": [
        "Dataframe storing the extracted features from encoder2 of autoencoder2)...These are numbered from 155(155 number of class variable column(y) has been ignored)"
      ],
      "id": "mjE2jEKJ__MW"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "e5b57485"
      },
      "outputs": [],
      "source": [
        "df3=pd.DataFrame(x_train_encode2)\n",
        "df4=pd.DataFrame(x_test_encode2)\n",
        "df3=df3.rename(columns={x:y for x,y in zip(df3.columns,range(155,205))})\n",
        "df4=df4.rename(columns={x:y for x,y in zip(df4.columns,range(155,205))})\n",
        "df3.columns =df3.columns.astype(str)\n",
        "df4.columns =df4.columns.astype(str)"
      ],
      "id": "e5b57485"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-4LOIUtADpe"
      },
      "source": [
        "Combining the original and extracted features(from encoder2 of autoencoder2)"
      ],
      "id": "b-4LOIUtADpe"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "c042249d"
      },
      "outputs": [],
      "source": [
        "x_train_com2 = pd.concat([x_train, df3], axis=1)\n",
        "x_test_com2=  pd.concat([x_test, df4], axis=1)"
      ],
      "id": "c042249d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ub78vXf9ALu-"
      },
      "source": [
        "Dataframe storing the extracted features from encoder 3 of autoencoder3...These are numbered from 155(155 number of class variable column(y) has been ignored)"
      ],
      "id": "Ub78vXf9ALu-"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0ad11423"
      },
      "outputs": [],
      "source": [
        "df1=pd.DataFrame(x_train_encode3)\n",
        "df2=pd.DataFrame(x_test_encode3)\n",
        "df1=df1.rename(columns={x:y for x,y in zip(df1.columns,range(155,180))})\n",
        "df2=df2.rename(columns={x:y for x,y in zip(df2.columns,range(155,180))})\n",
        "df1.columns =df1.columns.astype(str)\n",
        "df2.columns =df2.columns.astype(str)"
      ],
      "id": "0ad11423"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fop3bnykAQyV"
      },
      "source": [
        "Combining the original and extracted features(from encoder2 of autoencoder2)"
      ],
      "id": "fop3bnykAQyV"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "5ab6886d"
      },
      "outputs": [],
      "source": [
        "x_train_com3 = pd.concat([x_train, df1], axis=1)\n",
        "x_test_com3=  pd.concat([x_test, df2], axis=1)"
      ],
      "id": "5ab6886d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LAi1U5MAWJR"
      },
      "source": [
        "Running mutual information on extracted features(encoder2) + original features"
      ],
      "id": "9LAi1U5MAWJR"
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "1d605eb2"
      },
      "outputs": [],
      "source": [
        "mutual_info2 = pd.Series(mutual_info_classif(x_train_com2, y_train))\n",
        "mutual_info2.index = x_train_com2.columns"
      ],
      "id": "1d605eb2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc9d4de5",
        "outputId": "8f9571ba-d67c-4d9c-a686-b0fce9a7f715"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1     0.000000\n",
              "2     0.000000\n",
              "3     0.000000\n",
              "5     0.446422\n",
              "6     0.446206\n",
              "8     0.634048\n",
              "9     0.633909\n",
              "10    0.001152\n",
              "11    0.000869\n",
              "12    0.001806\n",
              "dtype: float64"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mutual_info2.head(10)"
      ],
      "id": "bc9d4de5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgdJl1F9Angh"
      },
      "source": [
        "Top 20 features after mutual information(original +encoder2 extracted)"
      ],
      "id": "LgdJl1F9Angh"
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67aa6624",
        "outputId": "9c3533fd-14ae-402d-9575-dcb3c3ed22ef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38     0.648676\n",
              "163    0.645748\n",
              "187    0.639052\n",
              "9      0.633967\n",
              "8      0.633400\n",
              "204    0.616267\n",
              "157    0.607321\n",
              "174    0.588542\n",
              "194    0.585607\n",
              "82     0.581619\n",
              "140    0.574374\n",
              "142    0.574344\n",
              "171    0.568055\n",
              "201    0.562260\n",
              "196    0.561568\n",
              "177    0.561537\n",
              "195    0.561145\n",
              "186    0.557297\n",
              "181    0.556807\n",
              "159    0.554390\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "mutual_info2.sort_values(ascending=False).head(20)"
      ],
      "id": "67aa6624"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqDLq8nMAwIZ"
      },
      "source": [
        "Creating a list of top 20"
      ],
      "id": "tqDLq8nMAwIZ"
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "d8cad25f"
      },
      "outputs": [],
      "source": [
        "mi2_top20=mutual_info2.sort_values(ascending=False).index[0:20].tolist()"
      ],
      "id": "d8cad25f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58585575",
        "outputId": "5378a507-4d65-4af3-faec-2d7c146efa00"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['38', '163', '187', '8', '9', '204', '157', '174', '194', '82',\n",
              "       ...\n",
              "       '83', '84', '85', '86', '87', '95', '96', '99', '100', '1'],\n",
              "      dtype='object', length=202)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mutual_info2.sort_values(ascending=False).index"
      ],
      "id": "58585575"
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "810abd80",
        "outputId": "341f1efd-d730-475b-d254-877123a19e44"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f14d67b9350>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "mutual_info2.sort_values(ascending=False).head(20).plot.bar(figsize=(20, 10))"
      ],
      "id": "810abd80"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xfmrjPsA1eJ"
      },
      "source": [
        "Running mutual information on extracted features(encoder3) + original features"
      ],
      "id": "4xfmrjPsA1eJ"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "9af98c61"
      },
      "outputs": [],
      "source": [
        "mutual_info3 = pd.Series(mutual_info_classif(x_train_com3, y_train))\n",
        "mutual_info3.index = x_train_com3.columns"
      ],
      "id": "9af98c61"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67d5c25a",
        "outputId": "89d00539-6b1c-4a38-ddde-173121552a2e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1     0.000759\n",
              "2     0.000948\n",
              "3     0.000000\n",
              "5     0.446311\n",
              "6     0.445944\n",
              "8     0.633100\n",
              "9     0.633070\n",
              "10    0.000000\n",
              "11    0.000000\n",
              "12    0.000314\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "mutual_info3.head(10)"
      ],
      "id": "67d5c25a"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f22a9759",
        "outputId": "54b3eec1-d63a-487e-e4c7-92cbadca2976"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "175    0.649871\n",
              "38     0.648651\n",
              "8      0.633100\n",
              "9      0.633070\n",
              "167    0.625455\n",
              "170    0.585055\n",
              "158    0.582275\n",
              "82     0.581508\n",
              "156    0.575179\n",
              "140    0.573958\n",
              "142    0.573336\n",
              "177    0.566826\n",
              "168    0.562797\n",
              "64     0.537865\n",
              "166    0.534780\n",
              "79     0.525675\n",
              "159    0.525513\n",
              "179    0.523351\n",
              "154    0.523071\n",
              "173    0.503575\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "mutual_info3.sort_values(ascending=False).head(20)"
      ],
      "id": "f22a9759"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "d6321178"
      },
      "outputs": [],
      "source": [
        "mi3_top20=mutual_info3.sort_values(ascending=False).index[0:20].tolist()"
      ],
      "id": "d6321178"
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "8f4eb50a",
        "outputId": "e6cdf2a1-1208-4fb5-b426-ab28270dc8e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f14d6b646d0>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "mutual_info3.sort_values(ascending=False).head(20).plot.bar(figsize=(20, 10))"
      ],
      "id": "8f4eb50a"
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "830f4fc4"
      },
      "outputs": [],
      "source": [
        "params_rf2 = {\n",
        "    'bootstrap': [True],\n",
        "    'max_depth': [5,10,15],\n",
        "    'max_features': ['auto'],\n",
        "    'min_samples_leaf': [4,5,6],\n",
        "    'min_samples_split': [4,5,6],\n",
        "    'n_estimators': [500,1000,1500,2000]\n",
        "}"
      ],
      "id": "830f4fc4"
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "0f6cfdc4"
      },
      "outputs": [],
      "source": [
        "ran_f2= RandomForestClassifier()"
      ],
      "id": "0f6cfdc4"
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "eb6100fa"
      },
      "outputs": [],
      "source": [
        "search_rf2 = RandomizedSearchCV(estimator = ran_f2, param_distributions = params_rf2, cv = 4, verbose = 2,n_jobs=-1)"
      ],
      "id": "eb6100fa"
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e91a38d",
        "outputId": "836ea742-d4f3-4a1d-9c54-c994b9359472"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=4, estimator=RandomForestClassifier(), n_jobs=-1,\n",
              "                   param_distributions={'bootstrap': [True],\n",
              "                                        'max_depth': [5, 10, 15],\n",
              "                                        'max_features': ['auto'],\n",
              "                                        'min_samples_leaf': [4, 5, 6],\n",
              "                                        'min_samples_split': [4, 5, 6],\n",
              "                                        'n_estimators': [500, 1000, 1500,\n",
              "                                                         2000]},\n",
              "                   verbose=2)"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "search_rf2.fit(x_train_com2[mi2_top20],y_train)"
      ],
      "id": "2e91a38d"
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9bda997",
        "outputId": "8311156e-be45-4262-c790-a4528e81490f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bootstrap': True,\n",
              " 'max_depth': 5,\n",
              " 'max_features': 'auto',\n",
              " 'min_samples_leaf': 5,\n",
              " 'min_samples_split': 5,\n",
              " 'n_estimators': 1000}"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "search_rf2.best_params_"
      ],
      "id": "c9bda997"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEbmBRIEBHkE"
      },
      "source": [
        "# Training different algorithms and testing them on test data to predict class variables"
      ],
      "id": "ZEbmBRIEBHkE"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wDlt2PrBPWy"
      },
      "source": [
        "Random forest model trained on top 20 obtained from MI on (orginal+ encoder2 extracted).With every iteration a variable is added to the trainig and prediction"
      ],
      "id": "7wDlt2PrBPWy"
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df0aaddd",
        "outputId": "4bac8893-ad41-449d-cf5c-e0973f3eff65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With top 1 predictors \n",
            "\n",
            "[[12371  7708]\n",
            " [    0 20079]]\n",
            "0.808058170227601\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 2 predictors \n",
            "\n",
            "[[11305  8774]\n",
            " [    0 20079]]\n",
            "0.7815130235569501\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 3 predictors \n",
            "\n",
            "[[17395  2684]\n",
            " [    3 20076]]\n",
            "0.9330892972757607\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 4 predictors \n",
            "\n",
            "[[17618  2461]\n",
            " [18608  1471]]\n",
            "0.475347377857463\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 5 predictors \n",
            "\n",
            "[[18348  1731]\n",
            " [18610  1469]]\n",
            "0.4934757707057124\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 6 predictors \n",
            "\n",
            "[[18616  1463]\n",
            " [18621  1458]]\n",
            "0.4998754918073609\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 7 predictors \n",
            "\n",
            "[[19234   845]\n",
            " [18470  1609]]\n",
            "0.5190248518352507\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 8 predictors \n",
            "\n",
            "[[19569   510]\n",
            " [18611  1468]]\n",
            "0.5238557697096469\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 9 predictors \n",
            "\n",
            "[[13767  6312]\n",
            " [18608  1471]]\n",
            "0.37945116788684696\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 10 predictors \n",
            "\n",
            "[[19442   637]\n",
            " [18615  1464]]\n",
            "0.5205936550625031\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 11 predictors \n",
            "\n",
            "[[19597   482]\n",
            " [18639  1440]]\n",
            "0.5238557697096469\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 12 predictors \n",
            "\n",
            "[[19867   212]\n",
            " [18617  1462]]\n",
            "0.531127048159769\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 13 predictors \n",
            "\n",
            "[[19962   117]\n",
            " [18643  1436]]\n",
            "0.5328452612181882\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 14 predictors \n",
            "\n",
            "[[19913   166]\n",
            " [18620  1459]]\n",
            "0.532197818616465\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 15 predictors \n",
            "\n",
            "[[19786   293]\n",
            " [18640  1439]]\n",
            "0.5285372777528762\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 16 predictors \n",
            "\n",
            "[[19877   202]\n",
            " [18540  1539]]\n",
            "0.5332934907116889\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 17 predictors \n",
            "\n",
            "[[19870   209]\n",
            " [18642  1437]]\n",
            "0.530579212112157\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 18 predictors \n",
            "\n",
            "[[19865   214]\n",
            " [18641  1438]]\n",
            "0.5304796055580457\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 19 predictors \n",
            "\n",
            "[[20017    62]\n",
            " [18676  1403]]\n",
            "0.5333930972658001\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 20 predictors \n",
            "\n",
            "[[19990    89]\n",
            " [18649  1430]]\n",
            "0.5333930972658001\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "rfmodel2 = RandomForestClassifier(n_estimators=30, criterion='gini', min_samples_split=10, min_samples_leaf=10, max_features='auto',max_depth=5, bootstrap=True, n_jobs=-1, random_state=42)\n",
        "for i in range(1,21):\n",
        "    mi2_top20=mutual_info2.sort_values(ascending=False).index[0:i].tolist()\n",
        "    rfmodel2.fit(x_train_com2[mi2_top20],y_train)\n",
        "    y_pred = rfmodel2.predict(x_test_com2[mi2_top20])\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    cm = confusion_matrix(y_test,y_pred)\n",
        "    print(\"With top\"+\" \"+str(i)+\" \"+ \"predictors\"+ \" \"+\"\\n\") \n",
        "    print(cm)\n",
        "    print(acc)\n",
        "    print(\"\\n\\n\\n\")"
      ],
      "id": "df0aaddd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DOYqtceBUoN"
      },
      "source": [
        "Random forest model trained on top 20 obtained from MI on (orginal+ encoder3 extracted).With every iteration a variable is added(MI Rankwise) to the training and prediction"
      ],
      "id": "5DOYqtceBUoN"
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e731bc1",
        "outputId": "1afa3cd3-1fbe-431d-e1a5-eb65097b4e6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With top 1 predictors \n",
            "\n",
            "[[19378   701]\n",
            " [15391  4688]]\n",
            "0.599282832810399\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 2 predictors \n",
            "\n",
            "[[12672  7407]\n",
            " [ 8257 11822]]\n",
            "0.6099407341003038\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 3 predictors \n",
            "\n",
            "[[14098  5981]\n",
            " [ 8257 11822]]\n",
            "0.6454504706409682\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 4 predictors \n",
            "\n",
            "[[15683  4396]\n",
            " [   12 20067]]\n",
            "0.8902335773693909\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 5 predictors \n",
            "\n",
            "[[19198   881]\n",
            " [ 8358 11721]]\n",
            "0.7699337616415161\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 6 predictors \n",
            "\n",
            "[[19599   480]\n",
            " [ 8269 11810]]\n",
            "0.7821355645201454\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 7 predictors \n",
            "\n",
            "[[19957   122]\n",
            " [12909  7170]]\n",
            "0.675506748344041\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 8 predictors \n",
            "\n",
            "[[19947   132]\n",
            " [18653  1426]]\n",
            "0.5322227202549927\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 9 predictors \n",
            "\n",
            "[[19814   265]\n",
            " [ 8591 11488]]\n",
            "0.7794710891976692\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 10 predictors \n",
            "\n",
            "[[19961   118]\n",
            " [12296  7783]]\n",
            "0.6908710593157029\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 11 predictors \n",
            "\n",
            "[[19757   322]\n",
            " [18609  1470]]\n",
            "0.5285870810299318\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 12 predictors \n",
            "\n",
            "[[20049    30]\n",
            " [18640  1439]]\n",
            "0.5350864086856916\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 13 predictors \n",
            "\n",
            "[[19987    92]\n",
            " [18647  1432]]\n",
            "0.5333681956272722\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 14 predictors \n",
            "\n",
            "[[19865   214]\n",
            " [18631  1448]]\n",
            "0.5307286219433238\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 15 predictors \n",
            "\n",
            "[[20042    37]\n",
            " [18712  1367]]\n",
            "0.5331191792419941\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 16 predictors \n",
            "\n",
            "[[20044    35]\n",
            " [18719  1360]]\n",
            "0.532994671049355\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 17 predictors \n",
            "\n",
            "[[20067    12]\n",
            " [18718  1361]]\n",
            "0.5335923103740227\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 18 predictors \n",
            "\n",
            "[[20047    32]\n",
            " [18657  1422]]\n",
            "0.5346132775536631\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 19 predictors \n",
            "\n",
            "[[20054    25]\n",
            " [18668  1411]]\n",
            "0.5345136709995517\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 20 predictors \n",
            "\n",
            "[[20066    13]\n",
            " [18708  1371]]\n",
            "0.533816425120773\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "rfmodel3 = RandomForestClassifier(n_estimators=30, criterion='gini', min_samples_split=2, min_samples_leaf=2, max_features='auto',max_depth=5, bootstrap=True,random_state=74)\n",
        "for i in range(1,21):\n",
        "    mi3_top20=mutual_info3.sort_values(ascending=False).index[0:i].tolist()\n",
        "    rfmodel3.fit(x_train_com3[mi3_top20],y_train)\n",
        "    y_pred = rfmodel3.predict(x_test_com3[mi3_top20])\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    cm = confusion_matrix(y_test,y_pred)\n",
        "    print(\"With top\"+\" \"+str(i)+\" \"+ \"predictors\"+ \" \"+\"\\n\") \n",
        "    print(cm)\n",
        "    print(acc)\n",
        "    print(\"\\n\\n\\n\")"
      ],
      "id": "0e731bc1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ef3b2168"
      },
      "outputs": [],
      "source": [
        "xgb_grid = {'gamma': [0,0.1,0.2,0.4,0.8,1.0,1.2,1.4,1.6,1.8,2.0],\n",
        "              'learning_rate': [0.01, 0.03, 0.06, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5, 0.6, 0.7],\n",
        "              'max_depth': [5,6,7,8,9,10,11,12,13,14],\n",
        "              'n_estimators': [50,65,80,100,115,130,150],\n",
        "              'reg_alpha': [0,0.1,0.2,0.4,0.8,1.0],\n",
        "              'reg_lambda': [0,0.1,0.2,0.4,0.8,1.0]}"
      ],
      "id": "ef3b2168"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5cd4b29"
      },
      "outputs": [],
      "source": [
        "xgb_3=  XGBClassifier()"
      ],
      "id": "c5cd4b29"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f36c6348"
      },
      "outputs": [],
      "source": [
        "search_xgb = GridSearchCV(estimator = xgb_3, param_grid = xgb_grid, cv = 4, verbose = 2,n_jobs=-1)"
      ],
      "id": "f36c6348"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56e657c3",
        "outputId": "948f9c2f-2c7d-4cd0-b3e7-6f946e49b983"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  1.7min\n",
            "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  2.2min finished\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[23:52:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=4,\n",
              "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
              "                                           colsample_bylevel=None,\n",
              "                                           colsample_bynode=None,\n",
              "                                           colsample_bytree=None,\n",
              "                                           enable_categorical=False, gamma=None,\n",
              "                                           gpu_id=None, importance_type=None,\n",
              "                                           interaction_constraints=None,\n",
              "                                           learning_rate=None,\n",
              "                                           max_delta_step=None, max_depth=None,\n",
              "                                           min_child_weight=None, missing=nan,\n",
              "                                           monotone_constraints...\n",
              "                                           validate_parameters=None,\n",
              "                                           verbosity=None),\n",
              "                   n_jobs=-1,\n",
              "                   param_distributions={'gamma': [0, 0.1, 0.2, 0.4, 0.8, 1.0,\n",
              "                                                  1.2, 1.4, 1.6, 1.8, 2.0],\n",
              "                                        'learning_rate': [0.01, 0.03, 0.06, 0.1,\n",
              "                                                          0.15, 0.2, 0.25, 0.3,\n",
              "                                                          0.4, 0.5, 0.6, 0.7],\n",
              "                                        'max_depth': [5, 6, 7, 8, 9, 10, 11, 12,\n",
              "                                                      13, 14],\n",
              "                                        'n_estimators': [50, 65, 80, 100, 115,\n",
              "                                                         130, 150],\n",
              "                                        'reg_alpha': [0, 0.1, 0.2, 0.4, 0.8,\n",
              "                                                      1.0],\n",
              "                                        'reg_lambda': [0, 0.1, 0.2, 0.4, 0.8,\n",
              "                                                       1.0]},\n",
              "                   verbose=2)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "search_xgb.fit(x_train_com3[mi3_top20],y_train)"
      ],
      "id": "56e657c3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "688ac3a0",
        "outputId": "3dd8b9b2-0e2c-4e66-fbd4-67511d64cc8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'reg_lambda': 0.8,\n",
              " 'reg_alpha': 0.8,\n",
              " 'n_estimators': 115,\n",
              " 'max_depth': 6,\n",
              " 'learning_rate': 0.4,\n",
              " 'gamma': 1.2}"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "search3_2.best_params_"
      ],
      "id": "688ac3a0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7Z-Nh6ABbr2"
      },
      "source": [
        "XG Boost model trained on top 20 obtained from MI on (orginal+ encoder2 extracted).With every iteration a variable is added(MI Rankwise) to the training and prediction"
      ],
      "id": "N7Z-Nh6ABbr2"
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CdY16OasvkP",
        "outputId": "2a56730d-a2e1-47fd-a619-cae3f8583f13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With top 1 predictors \n",
            "\n",
            "[[12371  7708]\n",
            " [    0 20079]]\n",
            "0.808058170227601\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 2 predictors \n",
            "\n",
            "[[12456  7623]\n",
            " [    0 20079]]\n",
            "0.8101748095024652\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 3 predictors \n",
            "\n",
            "[[17297  2782]\n",
            " [    0 20079]]\n",
            "0.9307236416156183\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 4 predictors \n",
            "\n",
            "[[12358  7721]\n",
            " [    0 20079]]\n",
            "0.8077344489267394\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 5 predictors \n",
            "\n",
            "[[12358  7721]\n",
            " [    0 20079]]\n",
            "0.8077344489267394\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 6 predictors \n",
            "\n",
            "[[12561  7518]\n",
            " [ 1872 18207]]\n",
            "0.7661736142238159\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 7 predictors \n",
            "\n",
            "[[12581  7498]\n",
            " [18603  1476]]\n",
            "0.3500423327854973\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 8 predictors \n",
            "\n",
            "[[12800  7279]\n",
            " [18605  1474]]\n",
            "0.3554459883460332\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 9 predictors \n",
            "\n",
            "[[13198  6881]\n",
            " [18612  1467]]\n",
            "0.3651825290104089\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 10 predictors \n",
            "\n",
            "[[13387  6692]\n",
            " [18606  1473]]\n",
            "0.37003834852333284\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 11 predictors \n",
            "\n",
            "[[13387  6692]\n",
            " [18606  1473]]\n",
            "0.37003834852333284\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 12 predictors \n",
            "\n",
            "[[13330  6749]\n",
            " [ 3653 16426]]\n",
            "0.740973156033667\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 13 predictors \n",
            "\n",
            "[[13459  6620]\n",
            " [ 3653 16426]]\n",
            "0.7441854674037551\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 14 predictors \n",
            "\n",
            "[[13314  6765]\n",
            " [ 3646 16433]]\n",
            "0.7407490412869167\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 15 predictors \n",
            "\n",
            "[[13314  6765]\n",
            " [ 3646 16433]]\n",
            "0.7407490412869167\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 16 predictors \n",
            "\n",
            "[[13393  6686]\n",
            " [ 3653 16426]]\n",
            "0.7425419592609194\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 17 predictors \n",
            "\n",
            "[[13252  6827]\n",
            " [18616  1463]]\n",
            "0.36642761093679965\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 18 predictors \n",
            "\n",
            "[[13249  6830]\n",
            " [18614  1465]]\n",
            "0.36640270929827184\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 19 predictors \n",
            "\n",
            "[[13194  6885]\n",
            " [18608  1471]]\n",
            "0.3651825290104089\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 20 predictors \n",
            "\n",
            "[[13106  6973]\n",
            " [ 4777 15302]]\n",
            "0.7074057472981722\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "xgbmodel2 = XGBClassifier(reg_lambda= 0.5,reg_alpha= 0.6,n_estimators= 30,max_depth=11,learning_rate= 0.4,gamma=1.2)\n",
        "for i in range(1,21):\n",
        "    mi2_top20=mutual_info2.sort_values(ascending=False).index[0:i].tolist()\n",
        "    xgbmodel2.fit(x_train_com2[mi2_top20],y_train)\n",
        "    y_pred = xgbmodel2.predict(x_test_com2[mi2_top20])\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    cm = confusion_matrix(y_test,y_pred)\n",
        "    print(\"With top\"+\" \"+str(i)+\" \"+ \"predictors\"+ \" \"+\"\\n\") \n",
        "    print(cm)\n",
        "    print(acc)\n",
        "    print(\"\\n\\n\\n\")"
      ],
      "id": "2CdY16OasvkP"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoDXJz0gBkp5"
      },
      "source": [
        "XG Boost model trained on top 20 obtained from MI on (orginal+ encoder3 extracted).With every iteration a variable is added(MI Rankwise) to the training and prediction"
      ],
      "id": "qoDXJz0gBkp5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "111b93f3",
        "outputId": "b5877f97-d1f8-47ce-8185-bda73f3e2934"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "With top 1 predictors \n",
            "\n",
            "[[19362   717]\n",
            " [15433  4646]]\n",
            "0.5978385377757857\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 2 predictors \n",
            "\n",
            "[[12486  7593]\n",
            " [ 3569 16510]]\n",
            "0.7220479107525275\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 3 predictors \n",
            "\n",
            "[[14636  5443]\n",
            " [    0 20079]]\n",
            "0.8644603814931022\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 4 predictors \n",
            "\n",
            "[[14636  5443]\n",
            " [    0 20079]]\n",
            "0.8644603814931022\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 5 predictors \n",
            "\n",
            "[[16374  3705]\n",
            " [ 8265 11814]]\n",
            "0.7019273868220529\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 6 predictors \n",
            "\n",
            "[[13831  6248]\n",
            " [18608  1471]]\n",
            "0.3810448727526271\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 7 predictors \n",
            "\n",
            "[[19388   691]\n",
            " [ 8264 11815]]\n",
            "0.7770058269834155\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 8 predictors \n",
            "\n",
            "[[17554  2525]\n",
            " [ 8257 11822]]\n",
            "0.7315105333930972\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 9 predictors \n",
            "\n",
            "[[16938  3141]\n",
            " [ 8257 11822]]\n",
            "0.7161711240599632\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 10 predictors \n",
            "\n",
            "[[17158  2921]\n",
            " [ 8257 11822]]\n",
            "0.7216494845360825\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 11 predictors \n",
            "\n",
            "[[16530  3549]\n",
            " [ 8257 11822]]\n",
            "0.7060112555406146\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 12 predictors \n",
            "\n",
            "[[17777  2302]\n",
            " [ 8287 11792]]\n",
            "0.7363165496289655\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 13 predictors \n",
            "\n",
            "[[17777  2302]\n",
            " [ 8287 11792]]\n",
            "0.7363165496289655\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 14 predictors \n",
            "\n",
            "[[13828  6251]\n",
            " [13380  6699]]\n",
            "0.5111559340604612\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 15 predictors \n",
            "\n",
            "[[19467   612]\n",
            " [ 2789 17290]]\n",
            "0.9153095273669007\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 16 predictors \n",
            "\n",
            "[[14519  5560]\n",
            " [ 4394 15685]]\n",
            "0.7521290900941282\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 17 predictors \n",
            "\n",
            "[[18913  1166]\n",
            " [ 8350 11729]]\n",
            "0.7630360077693112\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 18 predictors \n",
            "\n",
            "[[18913  1166]\n",
            " [ 8350 11729]]\n",
            "0.7630360077693112\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 19 predictors \n",
            "\n",
            "[[18959  1120]\n",
            " [ 8399 11680]]\n",
            "0.7629613028537278\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 20 predictors \n",
            "\n",
            "[[18899  1180]\n",
            " [ 8344 11735]]\n",
            "0.7628367946610887\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "xgbmodel3 = XGBClassifier(reg_lambda= 0.2,reg_alpha=0.5,n_estimators= 30 ,max_depth= 4,learning_rate= 1.2,gamma= 0.7)\n",
        "for i in range(1,21):\n",
        "    mi3_top20=mutual_info3.sort_values(ascending=False).index[0:i].tolist()\n",
        "    xgbmodel3.fit(x_train_com3[mi3_top20],y_train)\n",
        "    y_pred = xgbmodel3.predict(x_test_com3[mi3_top20])\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    cm = confusion_matrix(y_test,y_pred)\n",
        "    print(\"With top\"+\" \"+str(i)+\" \"+ \"predictors\"+ \" \"+\"\\n\") \n",
        "    print(cm)\n",
        "    print(acc)\n",
        "    print(\"\\n\\n\\n\")"
      ],
      "id": "111b93f3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBOTNK-WBubR"
      },
      "source": [
        "AdaBoost model trained on top 20 obtained from MI on (orginal+ encoder2 extracted).With every iteration a variable is added(MI Rankwise) to the training and prediction"
      ],
      "id": "rBOTNK-WBubR"
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_JS9nG3VVaw",
        "outputId": "4c4a936f-a162-46aa-c751-9a22f2bc778a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With top 1 predictors \n",
            "\n",
            "[[12371  7708]\n",
            " [    0 20079]]\n",
            "0.808058170227601\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 2 predictors \n",
            "\n",
            "[[16908  3171]\n",
            " [    3 20076]]\n",
            "0.9209621993127147\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 3 predictors \n",
            "\n",
            "[[17266  2813]\n",
            " [    3 20076]]\n",
            "0.9298769859056726\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 4 predictors \n",
            "\n",
            "[[19178   901]\n",
            " [  129 19950]]\n",
            "0.9743513123163504\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 5 predictors \n",
            "\n",
            "[[19178   901]\n",
            " [  129 19950]]\n",
            "0.9743513123163504\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 6 predictors \n",
            "\n",
            "[[19178   901]\n",
            " [  129 19950]]\n",
            "0.9743513123163504\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 7 predictors \n",
            "\n",
            "[[18312  1767]\n",
            " [  129 19950]]\n",
            "0.9527864933512625\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 8 predictors \n",
            "\n",
            "[[18312  1767]\n",
            " [  129 19950]]\n",
            "0.9527864933512625\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 9 predictors \n",
            "\n",
            "[[18312  1767]\n",
            " [  129 19950]]\n",
            "0.9527864933512625\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 10 predictors \n",
            "\n",
            "[[18310  1769]\n",
            " [  129 19950]]\n",
            "0.9527366900742069\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 11 predictors \n",
            "\n",
            "[[18312  1767]\n",
            " [  129 19950]]\n",
            "0.9527864933512625\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 12 predictors \n",
            "\n",
            "[[18312  1767]\n",
            " [  129 19950]]\n",
            "0.9527864933512625\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 13 predictors \n",
            "\n",
            "[[17092  2987]\n",
            " [    0 20079]]\n",
            "0.9256188057174162\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 14 predictors \n",
            "\n",
            "[[17163  2916]\n",
            " [    1 20078]]\n",
            "0.9273619204143633\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 15 predictors \n",
            "\n",
            "[[17094  2985]\n",
            " [    0 20079]]\n",
            "0.9256686089944718\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 16 predictors \n",
            "\n",
            "[[17366  2713]\n",
            " [    0 20079]]\n",
            "0.9324418546740375\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 17 predictors \n",
            "\n",
            "[[17693  2386]\n",
            " [    0 20079]]\n",
            "0.940584690472633\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 18 predictors \n",
            "\n",
            "[[17693  2386]\n",
            " [    0 20079]]\n",
            "0.940584690472633\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 19 predictors \n",
            "\n",
            "[[17221  2858]\n",
            " [    0 20079]]\n",
            "0.9288311170875043\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 20 predictors \n",
            "\n",
            "[[17221  2858]\n",
            " [    0 20079]]\n",
            "0.9288311170875043\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "adbmodel2 = AdaBoostClassifier(n_estimators=30,base_estimator=None, learning_rate = 0.15, random_state= 42)\n",
        "for i in range(1,21):\n",
        "    mi2_top20=mutual_info2.sort_values(ascending=False).index[0:i].tolist()\n",
        "    adbmodel2.fit(x_train_com2[mi2_top20],y_train)\n",
        "    y_pred = adbmodel2.predict(x_test_com2[mi2_top20])\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    cm = confusion_matrix(y_test,y_pred)\n",
        "    print(\"With top\"+\" \"+str(i)+\" \"+ \"predictors\"+ \" \"+\"\\n\") \n",
        "    print(cm)\n",
        "    print(acc)\n",
        "    print(\"\\n\\n\\n\")"
      ],
      "id": "B_JS9nG3VVaw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nla-G1sOBzWm"
      },
      "source": [
        "AdaBoost model trained on top 20 obtained from MI on (orginal+ encoder3 extracted).With every iteration a variable is added(MI Rankwise) to the training and prediction"
      ],
      "id": "nla-G1sOBzWm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fof1u0yXA-A",
        "outputId": "dbe4929d-dabd-40e0-a0b8-b8fd5357d444"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "With top 1 predictors \n",
            "\n",
            "[[19460   619]\n",
            " [15391  4688]]\n",
            "0.6013247671696798\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 2 predictors \n",
            "\n",
            "[[19460   619]\n",
            " [15391  4688]]\n",
            "0.6013247671696798\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 3 predictors \n",
            "\n",
            "[[19550   529]\n",
            " [20079     0]]\n",
            "0.4868270332187858\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 4 predictors \n",
            "\n",
            "[[19550   529]\n",
            " [20079     0]]\n",
            "0.4868270332187858\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 5 predictors \n",
            "\n",
            "[[19115   964]\n",
            " [18784  1295]]\n",
            "0.5082424423527068\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 6 predictors \n",
            "\n",
            "[[19364   715]\n",
            " [  197 19882]]\n",
            "0.9772897056626326\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 7 predictors \n",
            "\n",
            "[[19364   715]\n",
            " [  197 19882]]\n",
            "0.9772897056626326\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 8 predictors \n",
            "\n",
            "[[19711   368]\n",
            " [10546  9533]]\n",
            "0.7282235171074257\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 9 predictors \n",
            "\n",
            "[[19467   612]\n",
            " [  197 19882]]\n",
            "0.9798545744309975\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 10 predictors \n",
            "\n",
            "[[19165   914]\n",
            " [  150 19929]]\n",
            "0.9735046566064047\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 11 predictors \n",
            "\n",
            "[[19425   654]\n",
            " [  200 19879]]\n",
            "0.9787340006972459\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 12 predictors \n",
            "\n",
            "[[19425   654]\n",
            " [  200 19879]]\n",
            "0.9787340006972459\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 13 predictors \n",
            "\n",
            "[[19214   865]\n",
            " [  180 19899]]\n",
            "0.9739777877384332\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 14 predictors \n",
            "\n",
            "[[19214   865]\n",
            " [  180 19899]]\n",
            "0.9739777877384332\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 15 predictors \n",
            "\n",
            "[[19214   865]\n",
            " [  180 19899]]\n",
            "0.9739777877384332\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 16 predictors \n",
            "\n",
            "[[19272   807]\n",
            " [  596 19483]]\n",
            "0.9650630011454754\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 17 predictors \n",
            "\n",
            "[[19272   807]\n",
            " [  596 19483]]\n",
            "0.9650630011454754\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 18 predictors \n",
            "\n",
            "[[19272   807]\n",
            " [  596 19483]]\n",
            "0.9650630011454754\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 19 predictors \n",
            "\n",
            "[[19170   909]\n",
            " [  517 19562]]\n",
            "0.9644902634593356\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 20 predictors \n",
            "\n",
            "[[19170   909]\n",
            " [  517 19562]]\n",
            "0.9644902634593356\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "adbmodel3 = AdaBoostClassifier(n_estimators=30,base_estimator=None, learning_rate =0.1 , random_state= 42)\n",
        "for i in range(1,21):\n",
        "    mi3_top20=mutual_info3.sort_values(ascending=False).index[0:i].tolist()\n",
        "    adbmodel3.fit(x_train_com3[mi3_top20],y_train)\n",
        "    y_pred = adbmodel3.predict(x_test_com3[mi3_top20])\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    cm = confusion_matrix(y_test,y_pred)\n",
        "    print(\"With top\"+\" \"+str(i)+\" \"+ \"predictors\"+ \" \"+\"\\n\") \n",
        "    print(cm)\n",
        "    print(acc)\n",
        "    print(\"\\n\\n\\n\")"
      ],
      "id": "1fof1u0yXA-A"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnZ86QpjB6KW"
      },
      "source": [
        "SVM(Radial) model trained on top 20 obtained from MI on (orginal+ encoder2 extracted).With every iteration a variable is added(MI Rankwise) to the training and prediction"
      ],
      "id": "YnZ86QpjB6KW"
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okFRWIQhas2p",
        "outputId": "ae6129dc-262f-4163-ec2f-2de072a7b7c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With top 1 predictors \n",
            "\n",
            "[[   12 20067]\n",
            " [    0 20079]]\n",
            "0.5002988196623338\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 2 predictors \n",
            "\n",
            "[[   12 20067]\n",
            " [    0 20079]]\n",
            "0.5002988196623338\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 3 predictors \n",
            "\n",
            "[[17557  2522]\n",
            " [    6 20073]]\n",
            "0.9370486578016833\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 4 predictors \n",
            "\n",
            "[[16617  3462]\n",
            " [15894  4185]]\n",
            "0.5180038846556103\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 5 predictors \n",
            "\n",
            "[[19518   561]\n",
            " [ 6575 13504]]\n",
            "0.8223019074655112\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 6 predictors \n",
            "\n",
            "[[16704  3375]\n",
            " [    5 20074]]\n",
            "0.9158324617759849\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 7 predictors \n",
            "\n",
            "[[11559  8520]\n",
            " [15424  4655]]\n",
            "0.40375516708999454\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 8 predictors \n",
            "\n",
            "[[16738  3341]\n",
            " [    5 20074]]\n",
            "0.9166791174859306\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 9 predictors \n",
            "\n",
            "[[12555  7524]\n",
            " [14376  5703]]\n",
            "0.45465411624084867\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 10 predictors \n",
            "\n",
            "[[12153  7926]\n",
            " [14585  5494]]\n",
            "0.4394392151003536\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 11 predictors \n",
            "\n",
            "[[12153  7926]\n",
            " [14585  5494]]\n",
            "0.4394392151003536\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 12 predictors \n",
            "\n",
            "[[12153  7926]\n",
            " [14586  5493]]\n",
            "0.4394143134618258\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 13 predictors \n",
            "\n",
            "[[13057  7022]\n",
            " [   94 19985]]\n",
            "0.8227999402360675\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 14 predictors \n",
            "\n",
            "[[16804  3275]\n",
            " [ 1454 18625]]\n",
            "0.8822401514019622\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 15 predictors \n",
            "\n",
            "[[16821  3258]\n",
            " [ 7970 12109]]\n",
            "0.7204044026096917\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 16 predictors \n",
            "\n",
            "[[17121  2958]\n",
            " [   23 20056]]\n",
            "0.9257682155485831\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 17 predictors \n",
            "\n",
            "[[18937  1142]\n",
            " [16152  3927]]\n",
            "0.5693510632999651\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 18 predictors \n",
            "\n",
            "[[16905  3174]\n",
            " [11089  8990]]\n",
            "0.6448279296777728\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 19 predictors \n",
            "\n",
            "[[13387  6692]\n",
            " [  987 19092]]\n",
            "0.8087803177449077\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 20 predictors \n",
            "\n",
            "[[17256  2823]\n",
            " [14235  5844]]\n",
            "0.5752278499925295\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "rbfmodel2 = SVC(C=1,gamma=0.001, max_iter=100, random_state=42,kernel='rbf',verbose=0)\n",
        "for i in range(1,21):\n",
        "    mi2_top20=mutual_info2.sort_values(ascending=False).index[0:i].tolist()\n",
        "    rbfmodel2.fit(x_train_com2[mi2_top20],y_train)\n",
        "    y_pred = rbfmodel2.predict(x_test_com2[mi2_top20])\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    cm = confusion_matrix(y_test,y_pred)\n",
        "    print(\"With top\"+\" \"+str(i)+\" \"+ \"predictors\"+ \" \"+\"\\n\") \n",
        "    print(cm)\n",
        "    print(acc)\n",
        "    print(\"\\n\\n\\n\")"
      ],
      "id": "okFRWIQhas2p"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiNTWLHkCAUV"
      },
      "source": [
        "SVM(Radial) model trained on top 20 obtained from MI on (orginal+ encoder3 extracted).With every iteration a variable is added(MI Rankwise) to the training and prediction"
      ],
      "id": "uiNTWLHkCAUV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3gR_3IggCm3",
        "outputId": "9e37c092-c184-4a4b-b97e-b6ac6b948351"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "With top 1 predictors \n",
            "\n",
            "[[14340  5739]\n",
            " [ 1469 18610]]\n",
            "0.8205089894915085\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 2 predictors \n",
            "\n",
            "[[14270  5809]\n",
            " [ 1468 18611]]\n",
            "0.8187907764330893\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 3 predictors \n",
            "\n",
            "[[10586  9493]\n",
            " [18605  1474]]\n",
            "0.30031376064545046\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 4 predictors \n",
            "\n",
            "[[ 8285 11794]\n",
            " [ 4140 15939]]\n",
            "0.6032172916977937\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 5 predictors \n",
            "\n",
            "[[18429  1650]\n",
            " [ 1470 18609]]\n",
            "0.9223068877932168\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 6 predictors \n",
            "\n",
            "[[17020  3059]\n",
            " [ 1470 18609]]\n",
            "0.8872204791075253\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 7 predictors \n",
            "\n",
            "[[17395  2684]\n",
            " [18606  1473]]\n",
            "0.46984411574281587\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 8 predictors \n",
            "\n",
            "[[17833  2246]\n",
            " [18607  1472]]\n",
            "0.4807261317794711\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 9 predictors \n",
            "\n",
            "[[18008  2071]\n",
            " [18607  1472]]\n",
            "0.48508391852183874\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 10 predictors \n",
            "\n",
            "[[18016  2063]\n",
            " [18607  1472]]\n",
            "0.48528313163006126\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 11 predictors \n",
            "\n",
            "[[18026  2053]\n",
            " [18609  1470]]\n",
            "0.4854823447382838\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 12 predictors \n",
            "\n",
            "[[13674  6405]\n",
            " [18637  1442]]\n",
            "0.3764131679864535\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 13 predictors \n",
            "\n",
            "[[19284   795]\n",
            " [18609  1470]]\n",
            "0.5168086060062752\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 14 predictors \n",
            "\n",
            "[[19531   548]\n",
            " [18611  1468]]\n",
            "0.52290950744559\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 15 predictors \n",
            "\n",
            "[[19743   336]\n",
            " [18621  1458]]\n",
            "0.5279396384282086\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 16 predictors \n",
            "\n",
            "[[19588   491]\n",
            " [18612  1467]]\n",
            "0.5243039992031475\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 17 predictors \n",
            "\n",
            "[[19931   148]\n",
            " [18632  1447]]\n",
            "0.5323472284476318\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 18 predictors \n",
            "\n",
            "[[19931   148]\n",
            " [18632  1447]]\n",
            "0.5323472284476318\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 19 predictors \n",
            "\n",
            "[[19931   148]\n",
            " [18632  1447]]\n",
            "0.5323472284476318\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "With top 20 predictors \n",
            "\n",
            "[[20063    16]\n",
            " [18792  1287]]\n",
            "0.531649982568853\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "rbfmodel3 = SVC(C=1,gamma=0.09, max_iter=100, random_state=42,kernel='rbf',verbose=0)\n",
        "for i in range(1,21):\n",
        "    mi3_top20=mutual_info3.sort_values(ascending=False).index[0:i].tolist()\n",
        "    rbfmodel3.fit(x_train_com3[mi3_top20],y_train)\n",
        "    y_pred = rbfmodel3.predict(x_test_com3[mi3_top20])\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    cm = confusion_matrix(y_test,y_pred)\n",
        "    print(\"With top\"+\" \"+str(i)+\" \"+ \"predictors\"+ \" \"+\"\\n\") \n",
        "    print(cm)\n",
        "    print(acc)\n",
        "    print(\"\\n\\n\\n\")"
      ],
      "id": "-3gR_3IggCm3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pgo2gCKCLXx"
      },
      "source": [
        "# Running a LGBM wrapper to select a subset of the top 20 features obtained form MI of(original + extracted from encoder2)"
      ],
      "id": "8pgo2gCKCLXx"
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUTUpwmpjN7P",
        "outputId": "c2f793c5-e0ab-4344-9ed0-9124de710825"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['38', '163', '187', '9', '196']\n",
            "Runtime of the program is 3.148191213607788\n"
          ]
        }
      ],
      "source": [
        "start=time.time()\n",
        "model_gbm=LGBMClassifier(n_estimators=500, learning_rate=0.05, num_leaves=32, colsample_bytree=0.2,\n",
        "            reg_alpha=3, reg_lambda=1, min_split_gain=0.01, min_child_weight=40)\n",
        "bestmod_gbm = SelectFromModel(model_gbm, max_features=5)\n",
        "bestmod_gbm.fit(x_train_com2[mi2_top20],y_train)\n",
        "gbm_support = bestmod_gbm.get_support()\n",
        "gbm_selections = x_train_com2[mi2_top20].loc[:,gbm_support].columns.tolist()\n",
        "print(gbm_selections)\n",
        "end= time.time()\n",
        "print(f\"Runtime of the program is {end-start}\")\n"
      ],
      "id": "WUTUpwmpjN7P"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91Iss7piCUHy"
      },
      "source": [
        "Creating dataframe of the top 5 features as directed by LGBM wrapper"
      ],
      "id": "91Iss7piCUHy"
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "Oi8u5ZCPkEZs"
      },
      "outputs": [],
      "source": [
        "x_train2_extracted = x_train_com2[['38', '163', '187', '9', '196']]\n",
        "x_test2_extracted = x_test_com2[['38', '163', '187', '9', '196']]"
      ],
      "id": "Oi8u5ZCPkEZs"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0ilyvrCCYKz"
      },
      "source": [
        "Random forest model trained on top 5 obtained from LGBM. This model is an extension from encoder 2 side(Refer Roadmap section in Report to see genesis of this model)"
      ],
      "id": "Z0ilyvrCCYKz"
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AK4T4d4TlbA-",
        "outputId": "e113de53-0f86-4ed3-8f7e-eecc54435869"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification metrics for rfextracted2 are \n",
            "\n",
            "The confusion matrix is :\n",
            " [[18613  1466]\n",
            " [    0 20079]]\n",
            "The Accuracy is:  0.963494197918223 or 96.349 %\n",
            "The recall(tpr) is:  0.926988395836446 or 92.699 %\n",
            "The precision is:  1.0 or 100.0 %\n",
            "The False Positive Rate is:  0.0 or 0.0 %\n",
            "The False Negative Rate is:  0.07301160416355396 or 7.301 %\n",
            "The F-1 Score is:  0.9621110307040215 or 96.211 %\n",
            "The Matthews correlation coefficient is:  0.9294690639150514 or 92.947 %\n",
            "Runtime of the program is 52.6687228679657\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "rfextracted2 = RandomForestClassifier(n_estimators=1000, criterion='gini', min_samples_split= 10, min_samples_leaf=8, max_features='auto',max_depth=5, bootstrap=True, n_jobs=-1, random_state=42)\n",
        "rfextracted2.fit(x_train2_extracted,y_train)\n",
        "y_pred = rfextracted2.predict(x_test2_extracted)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "tp = cm[0][0]\n",
        "fn = cm[0][1]\n",
        "fp = cm[1][0]\n",
        "tn = cm[1][1]\n",
        "recall = tp/(tp+fn)\n",
        "precision = tp/(tp+fp) \n",
        "fpr = fp/(tn+fp)\n",
        "fnr = fn/(fn+tp)\n",
        "f1= 2 * (precision * recall) / (precision + recall)\n",
        "mcc = matthews_corrcoef(y_test,y_pred)\n",
        "print(\"The classification metrics for rfextracted2 are \\n\")\n",
        "print(\"The confusion matrix is :\\n \"+ str(cm))\n",
        "print(\"The Accuracy is: \",acc,\"or\",round(acc*100,3),\"%\")\n",
        "print(\"The recall(tpr) is: \",recall,\"or\",round(recall*100,3),\"%\")\n",
        "print(\"The precision is: \",precision,\"or\",round(precision*100,3),\"%\")\n",
        "print(\"The False Positive Rate is: \",fpr,\"or\",round(fpr*100,3),\"%\")\n",
        "print(\"The False Negative Rate is: \",fnr,\"or\",round(fnr*100,3),\"%\")\n",
        "print(\"The F-1 Score is: \",f1,\"or\",round(f1*100,3),\"%\")\n",
        "print(\"The Matthews correlation coefficient is: \",mcc,\"or\",round(mcc*100,3),\"%\")\n",
        "end = time.time()\n",
        "print(f\"Runtime of the program is {end-start}\")\n"
      ],
      "id": "AK4T4d4TlbA-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXjxChTzCb_K"
      },
      "source": [
        "XG Boost model trained on top 5 obtained from LGBM. This model is an extension from encoder 2 side(Refer Roadmap section in Report to see genesis of this model)"
      ],
      "id": "vXjxChTzCb_K"
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQ9z5SKbmvy9",
        "outputId": "dfa32924-0128-456e-cea7-69557d5b4bb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification metrics for xgbextracted2 are \n",
            "\n",
            "The confusion matrix is :\n",
            " [[12382  7697]\n",
            " [    1 20078]]\n",
            "The Accuracy is:  0.8083071866128791 or 80.831 %\n",
            "The recall(tpr) is:  0.6166641765028139 or 61.666 %\n",
            "The precision is:  0.9999192441250101 or 99.992 %\n",
            "The False Positive Rate is:  4.980327705563026e-05 or 0.005 %\n",
            "The False Negative Rate is:  0.3833358234971861 or 38.334 %\n",
            "The F-1 Score is:  0.7628611915470397 or 76.286 %\n",
            "The Matthews correlation coefficient is:  0.6675991166013439 or 66.76 %\n",
            "Runtime of the program is 2.305914878845215\n"
          ]
        }
      ],
      "source": [
        "start=time.time()\n",
        "xgbextracted2 = XGBClassifier(reg_lambda=0.5,reg_alpha=0.6,n_estimators= 30,max_depth=11,learning_rate= 0.4,gamma=1.2)\n",
        "xgbextracted2.fit(x_train2_extracted,y_train)\n",
        "y_pred = xgbextracted2.predict(x_test2_extracted)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "tp = cm[0][0]\n",
        "fn = cm[0][1]\n",
        "fp = cm[1][0]\n",
        "tn = cm[1][1]\n",
        "recall = tp/(tp+fn)\n",
        "precision = tp/(tp+fp) \n",
        "fpr = fp/(tn+fp)\n",
        "fnr = fn/(fn+tp)\n",
        "f1= 2 * (precision * recall) / (precision + recall)\n",
        "mcc = matthews_corrcoef(y_test,y_pred)\n",
        "print(\"The classification metrics for xgbextracted2 are \\n\")\n",
        "print(\"The confusion matrix is :\\n \"+ str(cm))\n",
        "print(\"The Accuracy is: \",acc,\"or\",round(acc*100,3),\"%\")\n",
        "print(\"The recall(tpr) is: \",recall,\"or\",round(recall*100,3),\"%\")\n",
        "print(\"The precision is: \",precision,\"or\",round(precision*100,3),\"%\")\n",
        "print(\"The False Positive Rate is: \",fpr,\"or\",round(fpr*100,3),\"%\")\n",
        "print(\"The False Negative Rate is: \",fnr,\"or\",round(fnr*100,3),\"%\")\n",
        "print(\"The F-1 Score is: \",f1,\"or\",round(f1*100,3),\"%\")\n",
        "print(\"The Matthews correlation coefficient is: \",mcc,\"or\",round(mcc*100,3),\"%\")\n",
        "end=time.time()\n",
        "print(f\"Runtime of the program is {end-start}\")\n"
      ],
      "id": "PQ9z5SKbmvy9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3j2LIqNSCg4R"
      },
      "source": [
        "Adaboost model trained on top 5 obtained from LGBM. This model is an extension from encoder 2 side(Refer Roadmap section in Report to see genesis of this model)"
      ],
      "id": "3j2LIqNSCg4R"
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txsDujbhnufa",
        "outputId": "27329349-8ccf-46df-c8c3-0525ea2dbf42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification metrics for adbextracted2 are \n",
            "\n",
            "The confusion matrix is :\n",
            " [[18686  1393]\n",
            " [   60 20019]]\n",
            "The Accuracy is:  0.9638179192190847 or 96.382 %\n",
            "The recall(tpr) is:  0.930624035061507 or 93.062 %\n",
            "The precision is:  0.9967993171876667 or 99.68 %\n",
            "The False Positive Rate is:  0.0029881966233378156 or 0.299 %\n",
            "The False Negative Rate is:  0.06937596493849295 or 6.938 %\n",
            "The F-1 Score is:  0.9625756600128783 or 96.258 %\n",
            "The Matthews correlation coefficient is:  0.929686821774473 or 92.969 %\n",
            "Runtime of the program is 2.798053503036499\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "adbextracted2 = AdaBoostClassifier(n_estimators=30,base_estimator=None, learning_rate = 0.15, random_state= 42)\n",
        "adbextracted2.fit(x_train2_extracted,y_train)\n",
        "y_pred = adbextracted2.predict(x_test2_extracted)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "tp = cm[0][0]\n",
        "fn = cm[0][1]\n",
        "fp = cm[1][0]\n",
        "tn = cm[1][1]\n",
        "recall = tp/(tp+fn)\n",
        "precision = tp/(tp+fp) \n",
        "fpr = fp/(tn+fp)\n",
        "fnr = fn/(fn+tp)\n",
        "f1= 2 * (precision * recall) / (precision + recall)\n",
        "mcc = matthews_corrcoef(y_test,y_pred)\n",
        "print(\"The classification metrics for adbextracted2 are \\n\")\n",
        "print(\"The confusion matrix is :\\n \"+ str(cm))\n",
        "print(\"The Accuracy is: \",acc,\"or\",round(acc*100,3),\"%\")\n",
        "print(\"The recall(tpr) is: \",recall,\"or\",round(recall*100,3),\"%\")\n",
        "print(\"The precision is: \",precision,\"or\",round(precision*100,3),\"%\")\n",
        "print(\"The False Positive Rate is: \",fpr,\"or\",round(fpr*100,3),\"%\")\n",
        "print(\"The False Negative Rate is: \",fnr,\"or\",round(fnr*100,3),\"%\")\n",
        "print(\"The F-1 Score is: \",f1,\"or\",round(f1*100,3),\"%\")\n",
        "print(\"The Matthews correlation coefficient is: \",mcc,\"or\",round(mcc*100,3),\"%\")\n",
        "end= time.time()\n",
        "print(f\"Runtime of the program is {end-start}\")"
      ],
      "id": "txsDujbhnufa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYthw39CCpM6"
      },
      "source": [
        "SVM(Radial) model trained on top 5 obtained from LGBM. This model is an extension from encoder 2 side(Refer Roadmap section in Report to see genesis of this model)"
      ],
      "id": "AYthw39CCpM6"
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-eMrSUupEWK",
        "outputId": "80e9ddaa-910d-4482-c786-818ee8bd41e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification metrics for rbfextracted2 are \n",
            "\n",
            "The confusion matrix is :\n",
            " [[19252   827]\n",
            " [ 1174 18905]]\n",
            "The Accuracy is:  0.9501718213058419 or 95.017 %\n",
            "The recall(tpr) is:  0.9588126898749938 or 95.881 %\n",
            "The precision is:  0.9425242338196417 or 94.252 %\n",
            "The False Positive Rate is:  0.058469047263309926 or 5.847 %\n",
            "The False Negative Rate is:  0.041187310125006225 or 4.119 %\n",
            "The F-1 Score is:  0.9505986915195656 or 95.06 %\n",
            "The Matthews correlation coefficient is:  0.9004781203478325 or 90.048 %\n",
            "Runtime of the program is 1.4851469993591309\n"
          ]
        }
      ],
      "source": [
        "start=time.time()\n",
        "rbfextracted2 = SVC(C=1,gamma=0.001, max_iter=100, random_state=42,kernel='rbf',verbose=0)\n",
        "rbfextracted2.fit(x_train2_extracted,y_train)\n",
        "y_pred = rbfextracted2.predict(x_test2_extracted)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "tp = cm[0][0]\n",
        "fn = cm[0][1]\n",
        "fp = cm[1][0]\n",
        "tn = cm[1][1]\n",
        "recall = tp/(tp+fn)\n",
        "precision = tp/(tp+fp) \n",
        "fpr = fp/(tn+fp)\n",
        "fnr = fn/(fn+tp)\n",
        "f1= 2 * (precision * recall) / (precision + recall)\n",
        "mcc = matthews_corrcoef(y_test,y_pred)\n",
        "print(\"The classification metrics for rbfextracted2 are \\n\")\n",
        "print(\"The confusion matrix is :\\n \"+ str(cm))\n",
        "print(\"The Accuracy is: \",acc,\"or\",round(acc*100,3),\"%\")\n",
        "print(\"The recall(tpr) is: \",recall,\"or\",round(recall*100,3),\"%\")\n",
        "print(\"The precision is: \",precision,\"or\",round(precision*100,3),\"%\")\n",
        "print(\"The False Positive Rate is: \",fpr,\"or\",round(fpr*100,3),\"%\")\n",
        "print(\"The False Negative Rate is: \",fnr,\"or\",round(fnr*100,3),\"%\")\n",
        "print(\"The F-1 Score is: \",f1,\"or\",round(f1*100,3),\"%\")\n",
        "print(\"The Matthews correlation coefficient is: \",mcc,\"or\",round(mcc*100,3),\"%\")\n",
        "end = time.time()\n",
        "print(f\"Runtime of the program is {end-start}\")"
      ],
      "id": "s-eMrSUupEWK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWa8K-7qCu_F"
      },
      "source": [
        "# Running a LGBM wrapper to select a subset of the top 20 features obtained form MI of(original + extracted from encoder3)"
      ],
      "id": "gWa8K-7qCu_F"
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EPTFyFKTfJt",
        "outputId": "655fe4ab-3081-4263-e3da-521efebccd46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['175', '38', '8', '170', '159']\n",
            "Runtime of the program is 3.054213762283325\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "model_gbm=LGBMClassifier(n_estimators=500, learning_rate=0.05, num_leaves=32, colsample_bytree=0.2,\n",
        "            reg_alpha=3, reg_lambda=1, min_split_gain=0.01, min_child_weight=40)\n",
        "bestmod_gbm = SelectFromModel(model_gbm, max_features=5)\n",
        "bestmod_gbm.fit(x_train_com3[mi3_top20],y_train)\n",
        "gbm_support = bestmod_gbm.get_support()\n",
        "gbm_selections3 = x_train_com3[mi3_top20].loc[:,gbm_support].columns.tolist()\n",
        "print(gbm_selections3)\n",
        "end = time.time()\n",
        "print(f\"Runtime of the program is {end-start}\")"
      ],
      "id": "6EPTFyFKTfJt"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONnDMCb-C6Od"
      },
      "source": [
        "Creating dataframe of the top 5 features as directed by LGBM wrapper"
      ],
      "id": "ONnDMCb-C6Od"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "3yI4kq6fU6nM"
      },
      "outputs": [],
      "source": [
        "x_train3_extracted = x_train_com3[['175', '38', '8', '170', '159']]"
      ],
      "id": "3yI4kq6fU6nM"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "EtBrL5uRZO1X"
      },
      "outputs": [],
      "source": [
        "x_test3_extracted = x_test_com3[['175', '38', '8', '170', '159']]"
      ],
      "id": "EtBrL5uRZO1X"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNqqgZzAC9id"
      },
      "source": [
        "SVM(radial) model trained on top 5 obtained from LGBM. This model is an extension from encoder 3 side(Refer Roadmap section in Report to see genesis of this model)"
      ],
      "id": "KNqqgZzAC9id"
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPCCzynkX7PC",
        "outputId": "e7a110c4-52ed-4700-e24a-4456287dc250"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification metrics for rbfextracted3 are \n",
            "\n",
            "The confusion matrix is :\n",
            " [[17945  2134]\n",
            " [ 1471 18608]]\n",
            "The Accuracy is:  0.9102295931072265 or 91.023 %\n",
            "The recall(tpr) is:  0.893719806763285 or 89.372 %\n",
            "The precision is:  0.9242377420683972 or 92.424 %\n",
            "The False Positive Rate is:  0.07326062054883212 or 7.326 %\n",
            "The False Negative Rate is:  0.10628019323671498 or 10.628 %\n",
            "The F-1 Score is:  0.9087226231168501 or 90.872 %\n",
            "The Matthews correlation coefficient is:  0.8209068224059788 or 82.091 %\n",
            "Runtime of the program is 1.5140948295593262\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "rbfextracted3 = SVC(C=0.5,gamma=0.7, max_iter=100, random_state=42,kernel='rbf',verbose=0)\n",
        "rbfextracted3.fit(x_train3_extracted,y_train)\n",
        "y_pred = rbfextracted3.predict(x_test3_extracted)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "tp = cm[0][0]\n",
        "fn = cm[0][1]\n",
        "fp = cm[1][0]\n",
        "tn = cm[1][1]\n",
        "recall = tp/(tp+fn)\n",
        "precision = tp/(tp+fp) \n",
        "fpr = fp/(tn+fp)\n",
        "fnr = fn/(fn+tp)\n",
        "f1= 2 * (precision * recall) / (precision + recall)\n",
        "mcc = matthews_corrcoef(y_test,y_pred)\n",
        "print(\"The classification metrics for rbfextracted3 are \\n\")\n",
        "print(\"The confusion matrix is :\\n \"+ str(cm))\n",
        "print(\"The Accuracy is: \",acc,\"or\",round(acc*100,3),\"%\")\n",
        "print(\"The recall(tpr) is: \",recall,\"or\",round(recall*100,3),\"%\")\n",
        "print(\"The precision is: \",precision,\"or\",round(precision*100,3),\"%\")\n",
        "print(\"The False Positive Rate is: \",fpr,\"or\",round(fpr*100,3),\"%\")\n",
        "print(\"The False Negative Rate is: \",fnr,\"or\",round(fnr*100,3),\"%\")\n",
        "print(\"The F-1 Score is: \",f1,\"or\",round(f1*100,3),\"%\")\n",
        "print(\"The Matthews correlation coefficient is: \",mcc,\"or\",round(mcc*100,3),\"%\")\n",
        "end = time.time()\n",
        "print(f\"Runtime of the program is {end-start}\")"
      ],
      "id": "sPCCzynkX7PC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0RmeGdrDBFx"
      },
      "source": [
        "Adaboost model trained on top 5 obtained from LGBM. This model is an extension from encoder 3 side(Refer Roadmap section in Report to see genesis of this model)"
      ],
      "id": "g0RmeGdrDBFx"
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJ8VrdM-a7ad",
        "outputId": "73e8c09e-8b9f-4f7c-ab1a-d397c1542f7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification metrics for adbextracted3 are \n",
            "\n",
            "The confusion matrix is :\n",
            " [[19461   618]\n",
            " [  129 19950]]\n",
            "The Accuracy is:  0.9813984760197221 or 98.14 %\n",
            "The recall(tpr) is:  0.9692215747796205 or 96.922 %\n",
            "The precision is:  0.9934150076569679 or 99.342 %\n",
            "The False Positive Rate is:  0.0064246227401763036 or 0.642 %\n",
            "The False Negative Rate is:  0.0307784252203795 or 3.078 %\n",
            "The F-1 Score is:  0.9811691749224836 or 98.117 %\n",
            "The Matthews correlation coefficient is:  0.9630826002514473 or 96.308 %\n",
            "Runtime of the program is 3.0054032802581787\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "adbextracted3 = AdaBoostClassifier(n_estimators=30,base_estimator=None, learning_rate =0.1 , random_state= 42)\n",
        "adbextracted3.fit(x_train3_extracted,y_train)\n",
        "y_pred = adbextracted3.predict(x_test3_extracted)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "tp = cm[0][0]\n",
        "fn = cm[0][1]\n",
        "fp = cm[1][0]\n",
        "tn = cm[1][1]\n",
        "recall = tp/(tp+fn)\n",
        "precision = tp/(tp+fp) \n",
        "fpr = fp/(tn+fp)\n",
        "fnr = fn/(fn+tp)\n",
        "f1= 2 * (precision * recall) / (precision + recall)\n",
        "mcc = matthews_corrcoef(y_test,y_pred)\n",
        "print(\"The classification metrics for adbextracted3 are \\n\")\n",
        "print(\"The confusion matrix is :\\n \"+ str(cm))\n",
        "print(\"The Accuracy is: \",acc,\"or\",round(acc*100,3),\"%\")\n",
        "print(\"The recall(tpr) is: \",recall,\"or\",round(recall*100,3),\"%\")\n",
        "print(\"The precision is: \",precision,\"or\",round(precision*100,3),\"%\")\n",
        "print(\"The False Positive Rate is: \",fpr,\"or\",round(fpr*100,3),\"%\")\n",
        "print(\"The False Negative Rate is: \",fnr,\"or\",round(fnr*100,3),\"%\")\n",
        "print(\"The F-1 Score is: \",f1,\"or\",round(f1*100,3),\"%\")\n",
        "print(\"The Matthews correlation coefficient is: \",mcc,\"or\",round(mcc*100,3),\"%\")\n",
        "end = time.time()\n",
        "print(f\"Runtime of the program is {end-start}\")"
      ],
      "id": "MJ8VrdM-a7ad"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXFXTJ6SDGLC"
      },
      "source": [
        "XG Boost model trained on top 5 obtained from LGBM. This model is an extension from encoder 3 side(Refer Roadmap section in Report to see genesis of this model)"
      ],
      "id": "WXFXTJ6SDGLC"
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZI0P-6_bdmZ",
        "outputId": "01d8b866-984e-4087-f039-a65206b41030"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification metrics for xgbextracted3 are \n",
            "\n",
            "The confusion matrix is :\n",
            " [[19184   895]\n",
            " [   41 20038]]\n",
            "The Accuracy is:  0.976692066337965 or 97.669 %\n",
            "The recall(tpr) is:  0.9554260670352109 or 95.543 %\n",
            "The precision is:  0.9978673602080624 or 99.787 %\n",
            "The False Positive Rate is:  0.0020419343592808408 or 0.204 %\n",
            "The False Negative Rate is:  0.044573932964789086 or 4.457 %\n",
            "The F-1 Score is:  0.9761856299613271 or 97.619 %\n",
            "The Matthews correlation coefficient is:  0.9542476264578714 or 95.425 %\n",
            "Runtime of the program is 1.1674108505249023\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "xgbextracted3 = XGBClassifier(reg_lambda=1,reg_alpha=0.5,n_estimators= 30 ,max_depth=2,learning_rate= 0.4,gamma= 0.1)\n",
        "xgbextracted3.fit(x_train3_extracted,y_train)\n",
        "y_pred = xgbextracted3.predict(x_test3_extracted)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "tp = cm[0][0]\n",
        "fn = cm[0][1]\n",
        "fp = cm[1][0]\n",
        "tn = cm[1][1]\n",
        "recall = tp/(tp+fn)\n",
        "precision = tp/(tp+fp) \n",
        "fpr = fp/(tn+fp)\n",
        "fnr = fn/(fn+tp)\n",
        "f1= 2 * (precision * recall) / (precision + recall)\n",
        "mcc = matthews_corrcoef(y_test,y_pred)\n",
        "print(\"The classification metrics for xgbextracted3 are \\n\")\n",
        "print(\"The confusion matrix is :\\n \"+ str(cm))\n",
        "print(\"The Accuracy is: \",acc,\"or\",round(acc*100,3),\"%\")\n",
        "print(\"The recall(tpr) is: \",recall,\"or\",round(recall*100,3),\"%\")\n",
        "print(\"The precision is: \",precision,\"or\",round(precision*100,3),\"%\")\n",
        "print(\"The False Positive Rate is: \",fpr,\"or\",round(fpr*100,3),\"%\")\n",
        "print(\"The False Negative Rate is: \",fnr,\"or\",round(fnr*100,3),\"%\")\n",
        "print(\"The F-1 Score is: \",f1,\"or\",round(f1*100,3),\"%\")\n",
        "print(\"The Matthews correlation coefficient is: \",mcc,\"or\",round(mcc*100,3),\"%\")\n",
        "end = time.time()\n",
        "print(f\"Runtime of the program is {end-start}\")"
      ],
      "id": "LZI0P-6_bdmZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msJPzCzqDNPJ"
      },
      "source": [
        "Random Forest model trained on top 5 obtained from LGBM. This model is an extension from encoder 3 side(Refer Roadmap section in Report to see genesis of this model)"
      ],
      "id": "msJPzCzqDNPJ"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDKubLvCcNAa",
        "outputId": "db328160-90ba-4b28-bba5-50fa99034b51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification metrics for rfextracted3 are \n",
            "\n",
            "The confusion matrix is :\n",
            " [[18904  1175]\n",
            " [ 8630 11449]]\n",
            "The Accuracy is:  0.7558394342347726 or 75.584 %\n",
            "The recall(tpr) is:  0.9414811494596345 or 94.148 %\n",
            "The precision is:  0.6865693324616837 or 68.657 %\n",
            "The False Positive Rate is:  0.42980228099008916 or 42.98 %\n",
            "The False Negative Rate is:  0.058518850540365555 or 5.852 %\n",
            "The F-1 Score is:  0.7940688467435364 or 79.407 %\n",
            "The Matthews correlation coefficient is:  0.5510695502328282 or 55.107 %\n",
            "Runtime of the program is 8.086498498916626\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "rfextracted3 = RandomForestClassifier(n_estimators=100, criterion='gini', min_samples_split=2, min_samples_leaf=2, max_features='auto',max_depth=20, bootstrap=True,random_state=42)\n",
        "rfextracted3.fit(x_train3_extracted,y_train)\n",
        "y_pred = rfextracted3.predict(x_test3_extracted)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "tp = cm[0][0]\n",
        "fn = cm[0][1]\n",
        "fp = cm[1][0]\n",
        "tn = cm[1][1]\n",
        "recall = tp/(tp+fn)\n",
        "precision = tp/(tp+fp) \n",
        "fpr = fp/(tn+fp)\n",
        "fnr = fn/(fn+tp)\n",
        "f1= 2 * (precision * recall) / (precision + recall)\n",
        "mcc = matthews_corrcoef(y_test,y_pred)\n",
        "print(\"The classification metrics for rfextracted3 are \\n\")\n",
        "print(\"The confusion matrix is :\\n \"+ str(cm))\n",
        "print(\"The Accuracy is: \",acc,\"or\",round(acc*100,3),\"%\")\n",
        "print(\"The recall(tpr) is: \",recall,\"or\",round(recall*100,3),\"%\")\n",
        "print(\"The precision is: \",precision,\"or\",round(precision*100,3),\"%\")\n",
        "print(\"The False Positive Rate is: \",fpr,\"or\",round(fpr*100,3),\"%\")\n",
        "print(\"The False Negative Rate is: \",fnr,\"or\",round(fnr*100,3),\"%\")\n",
        "print(\"The F-1 Score is: \",f1,\"or\",round(f1*100,3),\"%\")\n",
        "print(\"The Matthews correlation coefficient is: \",mcc,\"or\",round(mcc*100,3),\"%\")\n",
        "end = time.time()\n",
        "print(f\"Runtime of the program is {end-start}\")"
      ],
      "id": "rDKubLvCcNAa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaIuCt10DaQX"
      },
      "source": [
        "# Evaluation Metrics of above models"
      ],
      "id": "SaIuCt10DaQX"
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejWOGC3fZV_A",
        "outputId": "47af65c6-e0d3-4e8c-b2cd-68a04f64b144"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification metrics for rfmodel2 are \n",
            "\n",
            "The confusion matrix is :\n",
            " [[17395  2684]\n",
            " [    3 20076]]\n",
            "The Accuracy is:  0.9330892972757607 or 93.309 %\n",
            "The recall(tpr) is:  0.8663280043826884 or 86.633 %\n",
            "The precision is:  0.999827566386941 or 99.983 %\n",
            "The False Positive Rate is:  0.00014940983116689077 or 0.015 %\n",
            "The False Negative Rate is:  0.1336719956173116 or 13.367 %\n",
            "The F-1 Score is:  0.928302692317955 or 92.83 %\n",
            "The Matthews correlation coefficient is:  0.8740046326787453 or 87.4 %\n",
            "Runtime of the program is 1.3697068691253662\n"
          ]
        }
      ],
      "source": [
        "# Evaluating the rfmodel2 with top 3 predictors #\n",
        "start = time.time()\n",
        "rfmodel2 = RandomForestClassifier(n_estimators=30, criterion='gini', min_samples_split=10, min_samples_leaf=10, max_features='auto',max_depth=5, bootstrap=True, n_jobs=-1, random_state=42)\n",
        "best_x_train = x_train_com2[mutual_info2.sort_values(ascending=False).index[0:3].tolist()]\n",
        "best_x_test = x_test_com2[mutual_info2.sort_values(ascending=False).index[0:3].tolist()]\n",
        "rfmodel2.fit(best_x_train,y_train)\n",
        "y_pred = rfmodel2.predict(best_x_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "tp = cm[0][0]\n",
        "fn = cm[0][1]\n",
        "fp = cm[1][0]\n",
        "tn = cm[1][1]\n",
        "recall = tp/(tp+fn)\n",
        "precision = tp/(tp+fp) \n",
        "fpr = fp/(tn+fp)\n",
        "fnr = fn/(fn+tp)\n",
        "f1= 2 * (precision * recall) / (precision + recall)\n",
        "mcc = matthews_corrcoef(y_test,y_pred)\n",
        "print(\"The classification metrics for rfmodel2 are \\n\")\n",
        "print(\"The confusion matrix is :\\n \"+ str(cm))\n",
        "print(\"The Accuracy is: \",acc,\"or\",round(acc*100,3),\"%\")\n",
        "print(\"The recall(tpr) is: \",recall,\"or\",round(recall*100,3),\"%\")\n",
        "print(\"The precision is: \",precision,\"or\",round(precision*100,3),\"%\")\n",
        "print(\"The False Positive Rate is: \",fpr,\"or\",round(fpr*100,3),\"%\")\n",
        "print(\"The False Negative Rate is: \",fnr,\"or\",round(fnr*100,3),\"%\")\n",
        "print(\"The F-1 Score is: \",f1,\"or\",round(f1*100,3),\"%\")\n",
        "print(\"The Matthews correlation coefficient is: \",mcc,\"or\",round(mcc*100,3),\"%\")\n",
        "end = time.time()\n",
        "print(f\"Runtime of the program is {end-start}\")\n"
      ],
      "id": "ejWOGC3fZV_A"
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ikjp-diAfaEN",
        "outputId": "738f18eb-2ec4-4026-b793-55a6dbf71494"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification metrics for xgbmodel2 are \n",
            "\n",
            "The confusion matrix is :\n",
            " [[17297  2782]\n",
            " [    0 20079]]\n",
            "The Accuracy is:  0.9307236416156183 or 93.072 %\n",
            "The recall(tpr) is:  0.8614472832312366 or 86.145 %\n",
            "The precision is:  1.0 or 100.0 %\n",
            "The False Positive Rate is:  0.0 or 0.0 %\n",
            "The False Negative Rate is:  0.13855271676876338 or 13.855 %\n",
            "The F-1 Score is:  0.9255672089041096 or 92.557 %\n",
            "The Matthews correlation coefficient is:  0.8698368071299423 or 86.984 %\n",
            "Runtime of the program is 2.2071151733398438\n"
          ]
        }
      ],
      "source": [
        "# Evaluating the xgbmodel2 with top 3 predictors #\n",
        "start = time.time()\n",
        "xgbmodel2 = XGBClassifier(reg_lambda= 0.5,reg_alpha= 0.6,n_estimators= 30,max_depth=11,learning_rate= 0.4,gamma=1.2)\n",
        "best_x_train = x_train_com2[mutual_info2.sort_values(ascending=False).index[0:3].tolist()]\n",
        "best_x_test = x_test_com2[mutual_info2.sort_values(ascending=False).index[0:3].tolist()]\n",
        "xgbmodel2.fit(best_x_train,y_train)\n",
        "y_pred = xgbmodel2.predict(best_x_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "tp = cm[0][0]\n",
        "fn = cm[0][1]\n",
        "fp = cm[1][0]\n",
        "tn = cm[1][1]\n",
        "recall = tp/(tp+fn)\n",
        "precision = tp/(tp+fp) \n",
        "fpr = fp/(tn+fp)\n",
        "fnr = fn/(fn+tp)\n",
        "f1= 2 * (precision * recall) / (precision + recall)\n",
        "mcc = matthews_corrcoef(y_test,y_pred)\n",
        "print(\"The classification metrics for xgbmodel2 are \\n\")\n",
        "print(\"The confusion matrix is :\\n \"+ str(cm))\n",
        "print(\"The Accuracy is: \",acc,\"or\",round(acc*100,3),\"%\")\n",
        "print(\"The recall(tpr) is: \",recall,\"or\",round(recall*100,3),\"%\")\n",
        "print(\"The precision is: \",precision,\"or\",round(precision*100,3),\"%\")\n",
        "print(\"The False Positive Rate is: \",fpr,\"or\",round(fpr*100,3),\"%\")\n",
        "print(\"The False Negative Rate is: \",fnr,\"or\",round(fnr*100,3),\"%\")\n",
        "print(\"The F-1 Score is: \",f1,\"or\",round(f1*100,3),\"%\")\n",
        "print(\"The Matthews correlation coefficient is: \",mcc,\"or\",round(mcc*100,3),\"%\")\n",
        "end= time.time()\n",
        "print(f\"Runtime of the program is {end-start}\")\n"
      ],
      "id": "Ikjp-diAfaEN"
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-S4INV4Jfhwz",
        "outputId": "721806a3-6e50-43fe-f370-6729c9f35cd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification metrics for adbmodel2 are \n",
            "\n",
            "The confusion matrix is :\n",
            " [[19178   901]\n",
            " [  129 19950]]\n",
            "The Accuracy is:  0.9743513123163504 or 97.435 %\n",
            "The recall(tpr) is:  0.9551272473728771 or 95.513 %\n",
            "The precision is:  0.9933184855233853 or 99.332 %\n",
            "The False Positive Rate is:  0.0064246227401763036 or 0.642 %\n",
            "The False Negative Rate is:  0.04487275262712286 or 4.487 %\n",
            "The F-1 Score is:  0.9738485756360128 or 97.385 %\n",
            "The Matthews correlation coefficient is:  0.9494046169737584 or 94.94 %\n",
            "Runtime of the program is 2.368513345718384\n"
          ]
        }
      ],
      "source": [
        "# Evaluating the adbmodel2 with the top 4 predictors #\n",
        "start = time.time()\n",
        "adbmodel2 = AdaBoostClassifier(n_estimators=30,base_estimator=None, learning_rate = 0.15, random_state= 42)\n",
        "best_x_train = x_train_com2[mutual_info2.sort_values(ascending=False).index[0:4].tolist()]\n",
        "best_x_test = x_test_com2[mutual_info2.sort_values(ascending=False).index[0:4].tolist()]\n",
        "adbmodel2.fit(best_x_train,y_train)\n",
        "y_pred = adbmodel2.predict(best_x_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "\n",
        "tp = cm[0][0]\n",
        "fn = cm[0][1]\n",
        "fp = cm[1][0]\n",
        "tn = cm[1][1]\n",
        "recall = tp/(tp+fn)\n",
        "precision = tp/(tp+fp) \n",
        "fpr = fp/(tn+fp)\n",
        "fnr = fn/(fn+tp)\n",
        "f1= 2 * (precision * recall) / (precision + recall)\n",
        "mcc = matthews_corrcoef(y_test,y_pred)\n",
        "print(\"The classification metrics for adbmodel2 are \\n\")\n",
        "print(\"The confusion matrix is :\\n \"+ str(cm))\n",
        "print(\"The Accuracy is: \",acc,\"or\",round(acc*100,3),\"%\")\n",
        "print(\"The recall(tpr) is: \",recall,\"or\",round(recall*100,3),\"%\")\n",
        "print(\"The precision is: \",precision,\"or\",round(precision*100,3),\"%\")\n",
        "print(\"The False Positive Rate is: \",fpr,\"or\",round(fpr*100,3),\"%\")\n",
        "print(\"The False Negative Rate is: \",fnr,\"or\",round(fnr*100,3),\"%\")\n",
        "print(\"The F-1 Score is: \",f1,\"or\",round(f1*100,3),\"%\")\n",
        "print(\"The Matthews correlation coefficient is: \",mcc,\"or\",round(mcc*100,3),\"%\")\n",
        "end = time.time()\n",
        "print(f\"Runtime of the program is {end-start}\")"
      ],
      "id": "-S4INV4Jfhwz"
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yMZQR8MfhB8",
        "outputId": "160ea0c2-2799-4b72-d9b7-6ab4afe00780"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification metrics for rbfmodel2 are \n",
            "\n",
            "The confusion matrix is :\n",
            " [[17557  2522]\n",
            " [    6 20073]]\n",
            "The Accuracy is:  0.9370486578016833 or 93.705 %\n",
            "The recall(tpr) is:  0.8743961352657005 or 87.44 %\n",
            "The precision is:  0.9996583727153675 or 99.966 %\n",
            "The False Positive Rate is:  0.00029881966233378154 or 0.03 %\n",
            "The False Negative Rate is:  0.12560386473429952 or 12.56 %\n",
            "The F-1 Score is:  0.9328409755060836 or 93.284 %\n",
            "The Matthews correlation coefficient is:  0.8810414535582425 or 88.104 %\n",
            "Runtime of the program is 1.4055876731872559\n"
          ]
        }
      ],
      "source": [
        "# Evaluating the rbfmodel2 with the top 3 predictors #\n",
        "start= time.time()\n",
        "rbfmodel2 = SVC(C=1,gamma=0.001, max_iter=100, random_state=42,kernel='rbf',verbose=0)\n",
        "best_x_train = x_train_com2[mutual_info2.sort_values(ascending=False).index[0:3].tolist()]\n",
        "best_x_test = x_test_com2[mutual_info2.sort_values(ascending=False).index[0:3].tolist()]\n",
        "rbfmodel2.fit(best_x_train,y_train)\n",
        "y_pred = rbfmodel2.predict(best_x_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "tp = cm[0][0]\n",
        "fn = cm[0][1]\n",
        "fp = cm[1][0]\n",
        "tn = cm[1][1]\n",
        "recall = tp/(tp+fn)\n",
        "precision = tp/(tp+fp) \n",
        "fpr = fp/(tn+fp)\n",
        "fnr = fn/(fn+tp)\n",
        "f1= 2 * (precision * recall) / (precision + recall)\n",
        "mcc = matthews_corrcoef(y_test,y_pred)\n",
        "print(\"The classification metrics for rbfmodel2 are \\n\")\n",
        "print(\"The confusion matrix is :\\n \"+ str(cm))\n",
        "print(\"The Accuracy is: \",acc,\"or\",round(acc*100,3),\"%\")\n",
        "print(\"The recall(tpr) is: \",recall,\"or\",round(recall*100,3),\"%\")\n",
        "print(\"The precision is: \",precision,\"or\",round(precision*100,3),\"%\")\n",
        "print(\"The False Positive Rate is: \",fpr,\"or\",round(fpr*100,3),\"%\")\n",
        "print(\"The False Negative Rate is: \",fnr,\"or\",round(fnr*100,3),\"%\")\n",
        "print(\"The F-1 Score is: \",f1,\"or\",round(f1*100,3),\"%\")\n",
        "print(\"The Matthews correlation coefficient is: \",mcc,\"or\",round(mcc*100,3),\"%\")\n",
        "end = time.time()\n",
        "print(f\"Runtime of the program is {end-start}\")"
      ],
      "id": "0yMZQR8MfhB8"
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JctT4MTe8ztm",
        "outputId": "23226732-94ac-401f-cffb-ed0118125fba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification metrics for rfmodel3 are \n",
            "\n",
            "The confusion matrix is :\n",
            " [[15683  4396]\n",
            " [   12 20067]]\n",
            "The Accuracy is:  0.8902335773693909 or 89.023 %\n",
            "The recall(tpr) is:  0.7810647940634494 or 78.106 %\n",
            "The precision is:  0.9992354252946798 or 99.924 %\n",
            "The False Positive Rate is:  0.0005976393246675631 or 0.06 %\n",
            "The False Negative Rate is:  0.21893520593655064 or 21.894 %\n",
            "The F-1 Score is:  0.8767820204617879 or 87.678 %\n",
            "The Matthews correlation coefficient is:  0.799762787757569 or 79.976 %\n",
            "Runtime of the program is 1.768254041671753\n"
          ]
        }
      ],
      "source": [
        "# Evaluating the rfmodel3 with the top 4 predictors #\n",
        "start=time.time()\n",
        "rfmodel3 = RandomForestClassifier(n_estimators=30, criterion='gini', min_samples_split=2, min_samples_leaf=2, max_features='auto',max_depth=5, bootstrap=True,random_state=74)\n",
        "best_x_train = x_train_com3[mutual_info3.sort_values(ascending=False).index[0:4].tolist()]\n",
        "best_x_test = x_test_com3[mutual_info3.sort_values(ascending=False).index[0:4].tolist()]\n",
        "rfmodel3.fit(best_x_train,y_train)\n",
        "y_pred = rfmodel3.predict(best_x_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "tp = cm[0][0]\n",
        "fn = cm[0][1]\n",
        "fp = cm[1][0]\n",
        "tn = cm[1][1]\n",
        "recall = tp/(tp+fn)\n",
        "precision = tp/(tp+fp) \n",
        "fpr = fp/(tn+fp)\n",
        "fnr = fn/(fn+tp)\n",
        "f1= 2 * (precision * recall) / (precision + recall)\n",
        "mcc = matthews_corrcoef(y_test,y_pred)\n",
        "print(\"The classification metrics for rfmodel3 are \\n\")\n",
        "print(\"The confusion matrix is :\\n \"+ str(cm))\n",
        "print(\"The Accuracy is: \",acc,\"or\",round(acc*100,3),\"%\")\n",
        "print(\"The recall(tpr) is: \",recall,\"or\",round(recall*100,3),\"%\")\n",
        "print(\"The precision is: \",precision,\"or\",round(precision*100,3),\"%\")\n",
        "print(\"The False Positive Rate is: \",fpr,\"or\",round(fpr*100,3),\"%\")\n",
        "print(\"The False Negative Rate is: \",fnr,\"or\",round(fnr*100,3),\"%\")\n",
        "print(\"The F-1 Score is: \",f1,\"or\",round(f1*100,3),\"%\")\n",
        "print(\"The Matthews correlation coefficient is: \",mcc,\"or\",round(mcc*100,3),\"%\")\n",
        "end= time.time()\n",
        "print(f\"Runtime of the program is {end-start}\")"
      ],
      "id": "JctT4MTe8ztm"
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNGYKCu0944o",
        "outputId": "c0c9645e-06a4-45a5-abe4-4027be86b5d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification metrics for xgbmodel3 are \n",
            "\n",
            "The confusion matrix is :\n",
            " [[14636  5443]\n",
            " [    0 20079]]\n",
            "The Accuracy is:  0.8644603814931022 or 86.446 %\n",
            "The recall(tpr) is:  0.7289207629862045 or 72.892 %\n",
            "The precision is:  1.0 or 100.0 %\n",
            "The False Positive Rate is:  0.0 or 0.0 %\n",
            "The False Negative Rate is:  0.2710792370137955 or 27.108 %\n",
            "The F-1 Score is:  0.8432089874693937 or 84.321 %\n",
            "The Matthews correlation coefficient is:  0.7572753985889467 or 75.728 %\n",
            "Runtime of the program is 1.1742312908172607\n"
          ]
        }
      ],
      "source": [
        "# Evaluating the xgbmodel3 with the top 3 predictors #\n",
        "start = time.time()\n",
        "xgbmodel3 = XGBClassifier(reg_lambda= 0.2,reg_alpha=0.5,n_estimators= 30 ,max_depth= 4,learning_rate= 1.2,gamma= 0.7)\n",
        "best_x_train = x_train_com3[mutual_info3.sort_values(ascending=False).index[0:3].tolist()]\n",
        "best_x_test = x_test_com3[mutual_info3.sort_values(ascending=False).index[0:3].tolist()]\n",
        "xgbmodel3.fit(best_x_train,y_train)\n",
        "y_pred = xgbmodel3.predict(best_x_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "tp = cm[0][0]\n",
        "fn = cm[0][1]\n",
        "fp = cm[1][0]\n",
        "tn = cm[1][1]\n",
        "recall = tp/(tp+fn)\n",
        "precision = tp/(tp+fp) \n",
        "fpr = fp/(tn+fp)\n",
        "fnr = fn/(fn+tp)\n",
        "f1= 2 * (precision * recall) / (precision + recall)\n",
        "mcc = matthews_corrcoef(y_test,y_pred)\n",
        "print(\"The classification metrics for xgbmodel3 are \\n\")\n",
        "print(\"The confusion matrix is :\\n \"+ str(cm))\n",
        "print(\"The Accuracy is: \",acc,\"or\",round(acc*100,3),\"%\")\n",
        "print(\"The recall(tpr) is: \",recall,\"or\",round(recall*100,3),\"%\")\n",
        "print(\"The precision is: \",precision,\"or\",round(precision*100,3),\"%\")\n",
        "print(\"The False Positive Rate is: \",fpr,\"or\",round(fpr*100,3),\"%\")\n",
        "print(\"The False Negative Rate is: \",fnr,\"or\",round(fnr*100,3),\"%\")\n",
        "print(\"The F-1 Score is: \",f1,\"or\",round(f1*100,3),\"%\")\n",
        "print(\"The Matthews correlation coefficient is: \",mcc,\"or\",round(mcc*100,3),\"%\")\n",
        "end= time.time()\n",
        "print(f\"Runtime of the program is {end-start}\")"
      ],
      "id": "QNGYKCu0944o"
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1swA6xtA_Rty",
        "outputId": "f668720a-bff6-45cd-e5f1-a2e8554311c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification metrics for adbmodel3 are \n",
            "\n",
            "The confusion matrix is :\n",
            " [[19364   715]\n",
            " [  197 19882]]\n",
            "The Accuracy is:  0.9772897056626326 or 97.729 %\n",
            "The recall(tpr) is:  0.9643906569052244 or 96.439 %\n",
            "The precision is:  0.9899289402382291 or 98.993 %\n",
            "The False Positive Rate is:  0.009811245579959162 or 0.981 %\n",
            "The False Negative Rate is:  0.03560934309477563 or 3.561 %\n",
            "The F-1 Score is:  0.9769929364278507 or 97.699 %\n",
            "The Matthews correlation coefficient is:  0.9548972262401245 or 95.49 %\n",
            "Runtime of the program is 3.070345401763916\n"
          ]
        }
      ],
      "source": [
        "# Evaluating the model adbmodel3 with top 6 predictors #\n",
        "start = time.time()\n",
        "adbmodel3 = AdaBoostClassifier(n_estimators=30,base_estimator=None, learning_rate =0.1 , random_state= 42)\n",
        "best_x_train = x_train_com3[mutual_info3.sort_values(ascending=False).index[0:6].tolist()]\n",
        "best_x_test = x_test_com3[mutual_info3.sort_values(ascending=False).index[0:6].tolist()]\n",
        "adbmodel3.fit(best_x_train,y_train)\n",
        "y_pred = adbmodel3.predict(best_x_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "tp = cm[0][0]\n",
        "fn = cm[0][1]\n",
        "fp = cm[1][0]\n",
        "tn = cm[1][1]\n",
        "recall = tp/(tp+fn)\n",
        "precision = tp/(tp+fp) \n",
        "fpr = fp/(tn+fp)\n",
        "fnr = fn/(fn+tp)\n",
        "f1= 2 * (precision * recall) / (precision + recall)\n",
        "mcc = matthews_corrcoef(y_test,y_pred)\n",
        "print(\"The classification metrics for adbmodel3 are \\n\")\n",
        "print(\"The confusion matrix is :\\n \"+ str(cm))\n",
        "print(\"The Accuracy is: \",acc,\"or\",round(acc*100,3),\"%\")\n",
        "print(\"The recall(tpr) is: \",recall,\"or\",round(recall*100,3),\"%\")\n",
        "print(\"The precision is: \",precision,\"or\",round(precision*100,3),\"%\")\n",
        "print(\"The False Positive Rate is: \",fpr,\"or\",round(fpr*100,3),\"%\")\n",
        "print(\"The False Negative Rate is: \",fnr,\"or\",round(fnr*100,3),\"%\")\n",
        "print(\"The F-1 Score is: \",f1,\"or\",round(f1*100,3),\"%\")\n",
        "print(\"The Matthews correlation coefficient is: \",mcc,\"or\",round(mcc*100,3),\"%\")\n",
        "end = time.time()\n",
        "print(f\"Runtime of the program is {end-start}\")"
      ],
      "id": "1swA6xtA_Rty"
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQLaoa-FZxJA",
        "outputId": "335a5fc0-2f90-4199-ec12-7cd590608d47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification metrics for rbfmodel3 are \n",
            "\n",
            "The confusion matrix is :\n",
            " [[18429  1650]\n",
            " [ 1470 18609]]\n",
            "The Accuracy is:  0.9223068877932168 or 92.231 %\n",
            "The recall(tpr) is:  0.91782459285821 or 91.782 %\n",
            "The precision is:  0.9261269410523142 or 92.613 %\n",
            "The False Positive Rate is:  0.07321081727177649 or 7.321 %\n",
            "The False Negative Rate is:  0.08217540714178993 or 8.218 %\n",
            "The F-1 Score is:  0.9219570763920156 or 92.196 %\n",
            "The Matthews correlation coefficient is:  0.8446477158486054 or 84.465 %\n",
            "Runtime of the program is 1.5608155727386475\n"
          ]
        }
      ],
      "source": [
        "# Evaluating the model rbfmodel3 with top 5 predictors #\n",
        "start = time.time()\n",
        "rbfmodel3 = SVC(C=1,gamma=0.09, max_iter=100, random_state=42,kernel='rbf',verbose=0)\n",
        "best_x_train = x_train_com3[mutual_info3.sort_values(ascending=False).index[0:5].tolist()]\n",
        "best_x_test = x_test_com3[mutual_info3.sort_values(ascending=False).index[0:5].tolist()]\n",
        "rbfmodel3.fit(best_x_train,y_train)\n",
        "y_pred = rbfmodel3.predict(best_x_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "tp = cm[0][0]\n",
        "fn = cm[0][1]\n",
        "fp = cm[1][0]\n",
        "tn = cm[1][1]\n",
        "recall = tp/(tp+fn)\n",
        "precision = tp/(tp+fp) \n",
        "fpr = fp/(tn+fp)\n",
        "fnr = fn/(fn+tp)\n",
        "f1= 2 * (precision * recall) / (precision + recall)\n",
        "mcc = matthews_corrcoef(y_test,y_pred)\n",
        "print(\"The classification metrics for rbfmodel3 are \\n\")\n",
        "print(\"The confusion matrix is :\\n \"+ str(cm))\n",
        "print(\"The Accuracy is: \",acc,\"or\",round(acc*100,3),\"%\")\n",
        "print(\"The recall(tpr) is: \",recall,\"or\",round(recall*100,3),\"%\")\n",
        "print(\"The precision is: \",precision,\"or\",round(precision*100,3),\"%\")\n",
        "print(\"The False Positive Rate is: \",fpr,\"or\",round(fpr*100,3),\"%\")\n",
        "print(\"The False Negative Rate is: \",fnr,\"or\",round(fnr*100,3),\"%\")\n",
        "print(\"The F-1 Score is: \",f1,\"or\",round(f1*100,3),\"%\")\n",
        "print(\"The Matthews correlation coefficient is: \",mcc,\"or\",round(mcc*100,3),\"%\")\n",
        "end = time.time()\n",
        "print(f\"Runtime of the program is {end-start}\")"
      ],
      "id": "vQLaoa-FZxJA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZ3ZuvfwBnbM"
      },
      "outputs": [],
      "source": [
        ""
      ],
      "id": "NZ3ZuvfwBnbM"
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "AML_Coursework_per.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}